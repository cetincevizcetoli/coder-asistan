# ğŸ“ Proje DÃ¶kÃ¼mÃ¼: coder-asistan

Bu dÃ¶kÃ¼m, **D:\projects\coder-asistan** dizini iÃ§in oluÅŸturulmuÅŸtur.
Not: `my_projects` klasÃ¶rÃ¼nÃ¼n iÃ§eriÄŸi gizlilik gereÄŸi hariÃ§ tutulmuÅŸtur.

### ğŸ“‚ Proje Dizin YapÄ±sÄ± ve Dosyalar

- **coder-asistan/** (Proje KÃ¶kÃ¼)
  - .gitignore
  - ARCHITECTURE.md
  - assistant.py
  - check_models.py
  - config.py
  - debug.py
  - generate_docs.py
  - launcher.py
  - migrate_projects.py
  - model_selector.py
  - proje_dokumu.md
  - readme.md
  - requirements.txt
  - system_audit.py
  - **core/**
    - base.py
    - deepseek.py
    - gemini.py
    - groq.py
    - huggingface.py
    - memory.py
  - **my_projects/** (KullanÄ±cÄ± Projeleri - Ä°Ã§erik Gizli)

---
### ğŸ’» Kod Ä°Ã§eriÄŸi DÃ¶kÃ¼mÃ¼


#### ğŸ“„ Dosya: `ARCHITECTURE.md`

```md
# ğŸ—ï¸ Coder-Asistan: Teknik Mimari ve GeliÅŸtirici KÄ±lavuzu

Bu belge, **Coder-Asistan** projesinin iÃ§ yapÄ±sÄ±nÄ±, veri akÄ±ÅŸÄ±nÄ±, tasarÄ±m kararlarÄ±nÄ± ve sistemin "neden" bÃ¶yle Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± anlatan teknik referanstÄ±r.

Proje, basit bir script deÄŸil; modÃ¼ler, RAG (Retrieval-Augmented Generation) tabanlÄ± ve durum (state) korumalÄ± bir **CLI Kodlama StÃ¼dyosu**dur.

---

## 1. ğŸ—ºï¸ KuÅŸ BakÄ±ÅŸÄ± Sistem Mimarisi

Sistem 4 ana katmandan oluÅŸur:

1.  **YÃ¶netim KatmanÄ± (Launcher):** KullanÄ±cÄ±yÄ± karÅŸÄ±lar, proje izolasyonunu saÄŸlar ve Ã§alÄ±ÅŸma dizinini ayarlar.
2.  **Beyin KatmanÄ± (Assistant & Config):** KullanÄ±cÄ± isteÄŸini iÅŸler, maliyeti hesaplar ve AI'ya "JSON formatÄ±nda" emir verir.
3.  **HafÄ±za KatmanÄ± (RAG Core):** Projedeki kodlarÄ± vektÃ¶rleÅŸtirir (Embedding) ve anlamsal arama yapar.
4.  **AdaptÃ¶r KatmanÄ± (Model Core):** FarklÄ± AI saÄŸlayÄ±cÄ±larÄ±nÄ± (Gemini, Groq, HF) tek bir standart arayÃ¼ze dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.


```text
      [ KULLANICI ]
           â”‚
           â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   LAUNCHER.PY   â”‚  (1. GiriÅŸ KapÄ±sÄ± & Proje SeÃ§imi)
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  ASSISTANT.PY   â”‚ â—„â”€â”€â”€â–º â”‚  CONFIG (Kurallar)â”‚
  â”‚ (Karar Motoru)  â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ”€â”€â”€â–º [ ğŸ§  HAFIZA (RAG) ] â—„â”€â”€â”€ (.coder_memory)
           â”‚      (KodlarÄ± HatÄ±rlar)
           â”‚
           â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   MODEL CORE    â”‚  (AdaptÃ¶r KatmanÄ±)
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ”€â”€â”€â–º Google Gemini
           â”œâ”€â”€â”€â–º Groq Llama 3
           â””â”€â”€â”€â–º DeepSeek / HF

---

## 2. ğŸ“‚ Dizin YapÄ±sÄ± ve Sorumluluklar

```text
coder-asistan/
â”œâ”€â”€ launcher.py           # [ENTRY POINT] Proje seÃ§imi ve ortam hazÄ±rlÄ±ÄŸÄ±
â”œâ”€â”€ assistant.py          # [MAIN LOOP] Ä°stek-Cevap dÃ¶ngÃ¼sÃ¼ ve dosya iÅŸlemleri
â”œâ”€â”€ config.py             # [SETTINGS] Sabitler, Promptlar ve FiyatlandÄ±rma
â”œâ”€â”€ requirements.txt      # BaÄŸÄ±mlÄ±lÄ±klar
â”‚
â”œâ”€â”€ my_projects/          # [USER DATA] KullanÄ±cÄ± projelerinin fiziksel konumu
â”‚   â””â”€â”€ proje_x/          # -> Ä°zole Ã‡alÄ±ÅŸma AlanÄ±
â”‚       â”œâ”€â”€ .coder_memory/ # -> ChromaDB (VektÃ¶r VeritabanÄ±)
â”‚       â”œâ”€â”€ .chat_history/ # -> Loglar
â”‚       â””â”€â”€ src/           # -> KullanÄ±cÄ± KodlarÄ±
â”‚
â”œâ”€â”€ core/                 # [BACKEND] Sistem Ã§ekirdeÄŸi
â”‚   â”œâ”€â”€ base.py           # -> Soyut Model SÄ±nÄ±fÄ± (Interface)
â”‚   â”œâ”€â”€ memory.py         # -> RAG Motoru (SentenceTransformers + ChromaDB)
â”‚   â”œâ”€â”€ gemini.py         # -> Google Adapter
â”‚   â””â”€â”€ groq.py           # -> Groq Adapter
â”‚
â””â”€â”€ utils/ (Opsiyonel)    # YardÄ±mcÄ± araÃ§lar (debug.py, system_audit.py vb.)
```

---

## 3. âš™ï¸ Veri AkÄ±ÅŸÄ± (Bir Komutun YolculuÄŸu)

KullanÄ±cÄ± `python launcher.py` Ã§alÄ±ÅŸtÄ±rÄ±p bir projeye girdiÄŸinde ve "HatayÄ± dÃ¼zelt" dediÄŸinde arka planda ÅŸu olaylar zinciri gerÃ§ekleÅŸir:

### AdÄ±m 1: BaÄŸlamÄ±n YÃ¼klenmesi (Context Loading)
* `assistant.py`, `core.memory.MemoryManager`'Ä± baÅŸlatÄ±r.
* KullanÄ±cÄ±nÄ±n sorusu ("HatayÄ± dÃ¼zelt"), `SentenceTransformer` modeli ile **vektÃ¶re** (sayÄ±sal diziye) Ã§evrilir.
* ChromaDB iÃ§inde bu vektÃ¶re matematiksel olarak en yakÄ±n olan kod parÃ§alarÄ± (Chunks) bulunur.

### AdÄ±m 2: Prompt MÃ¼hendisliÄŸi (Prompt Engineering)
AI'ya giden metin ÅŸu ÅŸablonda birleÅŸtirilir:
1.  **Sistem Emri (`config.SYSTEM_INSTRUCTION`):** "Sen bir JSON makinesisin. Asla sohbet etme."
2.  **RAG BaÄŸlamÄ±:** "VeritabanÄ±ndan bulduÄŸum ilgili kodlar ÅŸunlar: ..."
3.  **KullanÄ±cÄ± Ä°steÄŸi:** "HatayÄ± dÃ¼zelt."

### AdÄ±m 3: Model Ã‡aÄŸrÄ±sÄ± ve Adaptasyon
* SeÃ§ili model (Ã–rn: Gemini), `core/gemini.py` Ã¼zerinden Ã§aÄŸrÄ±lÄ±r.
* Her model farklÄ± yanÄ±t verse de (Object, Dict, Text), adaptÃ¶rler bunu standart bir formata Ã§evirir.

### AdÄ±m 4: JSON TemizliÄŸi ve GÃ¼venlik
* AI'dan gelen yanÄ±t `clean_json_string()` fonksiyonuna girer. Markdown etiketleri (` ```json `) temizlenir.
* Saf JSON parse edilir.
* **GÃ¼venlik:** AI "BilgisayarÄ± kapat" diyemez. Sadece `dosya_olustur` veya `dosya_sil` komutlarÄ± iÅŸlenir.

### AdÄ±m 5: Ä°ÅŸlem ve Yedekleme
* Dosya yazÄ±lmadan Ã¶nce `backup_file()` fonksiyonu devreye girer.
* Hedef dosyanÄ±n bir kopyasÄ± `.gassist_backups` klasÃ¶rÃ¼ne zaman damgasÄ±yla (timestamp) kaydedilir.
* Yeni iÃ§erik yazÄ±lÄ±r.

---

## 4. ğŸ”§ Kritik KonfigÃ¼rasyonlar (`config.py`)

GeliÅŸtiricilerin bilmesi gereken hassas ayarlar:

* **`SYSTEM_INSTRUCTION`:** Sistemsel prompt. AI'nÄ±n "Suskun" olmasÄ±nÄ± saÄŸlayan yer burasÄ±dÄ±r. Buradaki kurallar gevÅŸetilirse sistemin JSON parse yeteneÄŸi bozulabilir.
* **`MAX_FILE_SIZE`:** VarsayÄ±lan 5MB. AI'nÄ±n token limitini patlatmamasÄ± iÃ§in bÃ¼yÃ¼k dosyalar (loglar, binaryler) okunmaz.
* **`PRICING_RATES`:** Maliyet hesaplama tablosu. Statiktir, API fiyatlarÄ± deÄŸiÅŸirse manuel gÃ¼ncellenmelidir.

---

## 5. ğŸ› ï¸ GeliÅŸtirici AraÃ§ Seti (DevTools)

Projeyi debug etmek veya yÃ¶netmek iÃ§in kullanÄ±lan "Ä°sviÃ§re Ã‡akÄ±sÄ±" araÃ§larÄ±:

| AraÃ§ | Dosya | GÃ¶revi |
| :--- | :--- | :--- |
| **HafÄ±za MÃ¼fettiÅŸi** | `debug.py` | ChromaDB veritabanÄ±na baÄŸlanÄ±r, vektÃ¶rleri ve kayÄ±tlÄ± kod parÃ§alarÄ±nÄ± ham haliyle gÃ¶sterir. |
| **Sistem Doktoru** | `system_audit.py` | Dosya izinlerini, log boyutlarÄ±nÄ± ve veritabanÄ± bÃ¼tÃ¼nlÃ¼ÄŸÃ¼nÃ¼ (integrity) kontrol eder. |
| **Proje TaÅŸÄ±yÄ±cÄ±** | `migrate_projects.py` | `my_projects` dÄ±ÅŸÄ±ndaki "sahipsiz" projeleri bulup iÃ§eriye taÅŸÄ±r. |
| **Belgeleyici** | `generate_docs.py` | TÃ¼m kod yapÄ±sÄ±nÄ± tek bir Markdown dosyasÄ±na dÃ¶ker (LLM analizi iÃ§in). |

---

## 6. ğŸš€ Gelecek PlanlarÄ± ve GeniÅŸletilebilirlik

Bu mimari ÅŸunlara izin verecek ÅŸekilde tasarlanmÄ±ÅŸtÄ±r:
* **Yeni Model Ekleme:** Sadece `core/` altÄ±na yeni bir `.py` dosyasÄ± ekleyerek.
* **Resim DesteÄŸi:** `assistant.py` gÃ¼ncellenerek Gemini 1.5 Pro'nun Vision Ã¶zellikleri aÃ§Ä±labilir.
* **Web ArayÃ¼zÃ¼:** Logic (MantÄ±k) ve UI (ArayÃ¼z) ayrÄ±ldÄ±ÄŸÄ± iÃ§in, `launcher.py` yerine bir `app.py` (Flask/Streamlit) yazÄ±larak kolayca web'e taÅŸÄ±nabilir.

---
**GeliÅŸtirici:** Ahmet Ã‡etin
*Bu dokÃ¼man Coder-Asistan v2.0 mimarisini yansÄ±tÄ±r.*
```

#### ğŸ“„ Dosya: `assistant.py`

```py
import sys
import os
import re
import json
import shutil
import time
import requests
from datetime import datetime
from typing import List, Optional, Any, Tuple, Dict

# --- PROJE MODÃœLLERÄ° ---
import config
from config import Colors, PRICING_RATES
from core.memory import MemoryManager

# --- DÄ°NAMÄ°K MODEL Ä°MPORTLARI ---
try: from core.gemini import GeminiModel
except ImportError: pass
try: from core.groq import GroqModel; GROQ_AVAILABLE = True
except ImportError: GROQ_AVAILABLE = False
try: from core.deepseek import DeepSeekModel; DEEPSEEK_AVAILABLE = True
except ImportError: DEEPSEEK_AVAILABLE = False
try: from core.huggingface import HuggingFaceModel; HF_AVAILABLE = True
except ImportError: HF_AVAILABLE = False

# --- SABÄ°TLER ---
FILE_PATTERN = re.compile(r"[\w-]+\.(py|js|html|css|md|json|txt|java|cpp|h|ts|jsx|tsx|sh|env)", re.IGNORECASE)

# ==========================================
# ğŸ› ï¸ YARDIMCI FONKSÄ°YONLAR
# ==========================================

def is_safe_path(file_path: str, current_directory: str) -> bool:
    if os.path.isabs(file_path): return False
    normalized_path = os.path.normpath(file_path)
    if normalized_path.startswith('..'): return False
    full_path = os.path.join(current_directory, file_path)
    return os.path.realpath(full_path).startswith(current_directory)

def clean_json_string(json_string: str) -> Optional[Dict]:
    """
    AI'dan gelen yanÄ±tÄ± temizler ve parse eder.
    GELÄ°ÅTÄ°RÄ°LMÄ°Å VERSÄ°YON: Hata olursa programÄ± Ã§Ã¶kertmek yerine None dÃ¶ner.
    """
    try:
        # Markdown kod bloklarÄ±nÄ± temizle (```json ... ```)
        if "```" in json_string:
            lines = json_string.split('\n')
            clean_lines = []
            capture = False
            for line in lines:
                if "```" in line:
                    capture = not capture # Blok baÅŸladÄ±/bitti
                    continue
                if capture:
                    clean_lines.append(line)
            
            # EÄŸer kod bloÄŸu bulduysak onu kullan, bulamadÄ±ysak (sadece ``` varsa) ham metni temizle
            if clean_lines:
                json_string = "\n".join(clean_lines)
            else:
                json_string = json_string.replace("```json", "").replace("```", "")

        # Temizlik sonrasÄ± kalan boÅŸluklarÄ± al
        json_string = json_string.strip()
        
        # OlasÄ± fazlalÄ±klarÄ± temizle (Bazen AI en sona aÃ§Ä±klama ekler)
        if json_string.rfind('}') != -1:
            json_string = json_string[:json_string.rfind('}')+1]

        # JSON Parse Denemesi
        return json.loads(json_string)

    except json.JSONDecodeError:
        print(f"\n{Colors.RED}âŒ AI YanÄ±tÄ± JSON FormatÄ±na Uymuyor!{Colors.RESET}")
        return None
    except Exception as e:
        print(f"{Colors.RED}âŒ Beklenmeyen JSON HatasÄ±: {e}{Colors.RESET}")
        return None

def backup_file(full_path: str) -> Optional[str]:
    if not os.path.exists(full_path): return None
    os.makedirs(config.BACKUP_DIR, exist_ok=True)
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    backup_name = f"{os.path.basename(full_path)}.{timestamp}.backup"
    shutil.copy(full_path, os.path.join(config.BACKUP_DIR, backup_name))
    return backup_name

def extract_wait_time(error_message: str) -> int:
    match = re.search(r"retry in (\d+(\.\d+)?)s", str(error_message))
    if match: return int(float(match.group(1))) + 2 
    return 30 

def log_conversation(working_dir: str, user_prompt: str, ai_explanation: str, model_name: str, cost: float = 0.0):
    """Sohbeti ve MALÄ°YETÄ° detaylÄ± ÅŸekilde log dosyasÄ±na kaydeder."""
    log_file = os.path.join(working_dir, ".chat_history.log")
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M')
    
    log_entry = (
        f"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
        f"ğŸ“… ZAMAN: {timestamp} | ğŸ¤– MODEL: {model_name}\n"
        f"ğŸ’° MALÄ°YET: ${cost:.5f}\n"
        f"ğŸ‘¤ USER: {user_prompt}\n"
        f"ğŸ¤– AI:   {ai_explanation}\n"
    )
    try:
        with open(log_file, "a", encoding="utf-8") as f:
            f.write(log_entry)
    except Exception as e:
        print(f"{Colors.RED}Log Yazma HatasÄ±: {e}{Colors.RESET}")

def update_project_stats(working_dir: str, usage_data: dict, model_key: str) -> Tuple[float, float]:
    """Toplam proje maliyetini hesaplar, kaydeder ve dÃ¶ner."""
    stats_file = os.path.join(working_dir, ".project_stats.json")
    
    stats = {
        "total_cost": 0.0,
        "total_input_tokens": 0,
        "total_output_tokens": 0,
        "last_updated": ""
    }

    if os.path.exists(stats_file):
        try:
            with open(stats_file, 'r', encoding='utf-8') as f:
                stats = json.load(f)
        except: pass

    in_tokens = usage_data.get("input_tokens", 0)
    out_tokens = usage_data.get("output_tokens", 0)
    rates = PRICING_RATES.get(model_key, {"input": 0, "output": 0})
    
    current_cost = ((in_tokens / 1_000_000) * rates["input"]) + ((out_tokens / 1_000_000) * rates["output"])

    stats["total_cost"] += current_cost
    stats["total_input_tokens"] += in_tokens
    stats["total_output_tokens"] += out_tokens
    stats["last_updated"] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

    try:
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=4)
    except Exception as e:
        print(f"{Colors.RED}Ä°statistik kayÄ±t hatasÄ±: {e}{Colors.RESET}")

    return current_cost, stats["total_cost"]

def print_cost_report(current_cost: float, total_cost: float, usage_data: dict):
    in_tokens = usage_data.get("input_tokens", 0)
    out_tokens = usage_data.get("output_tokens", 0)

    tier_label = "ÃœCRETSÄ°Z KATMAN" if config.USER_TIER == 'free' else "ÃœCRETLÄ° API"
    
    if config.USER_TIER == 'free':
        c_cost_str = "$0.00000"
        t_cost_str = "$0.00000"
    else:
        c_cost_str = f"${current_cost:.5f}"
        t_cost_str = f"${total_cost:.5f}"

    print(f"\n{Colors.GREY}ğŸ“Š FÄ°NANSAL RAPOR ({tier_label}){Colors.RESET}")
    print(f"{Colors.GREY}   â”œâ”€â”€ Bu Ä°ÅŸlem:  Girdi: {in_tokens:<5} | Ã‡Ä±ktÄ±: {out_tokens:<5} | Maliyet: {Colors.GREEN}{c_cost_str}{Colors.RESET}")
    print(f"{Colors.GREY}   â””â”€â”€ ğŸ’° TOPLAM: {Colors.CYAN}Proje Geneli Harcama: {t_cost_str}{Colors.RESET}")

# ==========================================
# ğŸš€ ANA Ä°ÅLEM DÃ–NGÃœSÃœ
# ==========================================

def main_process(prompt_text: str, model_instance: Any, working_dir: str, is_dry_run: bool = False):
    
    try: memory = MemoryManager(project_root=working_dir)
    except: memory = None

    if memory:
        all_files = []
        for root, dirs, files in os.walk(working_dir):
            dirs[:] = [d for d in dirs if not d.startswith('.')]
            for file in files:
                if FILE_PATTERN.match(file):
                    rel_path = os.path.relpath(os.path.join(root, file), working_dir)
                    all_files.append(rel_path)
        if all_files: memory.index_files(all_files)

    rag_context = ""
    if memory:
        print(f"{Colors.CYAN}ğŸ” HafÄ±za taranÄ±yor...{Colors.RESET}")
        rag_context = memory.query(prompt_text, n_results=config.MAX_CONTEXT_RESULTS)
        if len(rag_context) > config.MAX_CONTEXT_CHARS:
            rag_context = rag_context[:config.MAX_CONTEXT_CHARS] + "\n...(KÄ±rpÄ±ldÄ±)..."

    full_prompt = (
        f"--- PROJE BAÄLAMI ---\n{rag_context}\n\n"
        f"--- KULLANICI Ä°STEÄÄ° ---\n{prompt_text}\n"
    )
        
    print(f"{Colors.BLUE}âœ… GÃ–REV:{Colors.RESET} {prompt_text}")
    if is_dry_run: print(f"{Colors.YELLOW}ğŸ§ª (DRY-RUN AKTÄ°F){Colors.RESET}")

    ai_response_plan = {} 
    
    # Maliyet deÄŸiÅŸkenleri
    current_cost = 0.0
    total_cost = 0.0

    # 4. MODEL Ã‡ALIÅTIRMA
    while True:
        masked_key = os.getenv("GOOGLE_API_KEY", "")[:5] + "..."
        print(f"{Colors.CYAN}â³ {model_instance.MODEL_NAME} dÃ¼ÅŸÃ¼nÃ¼yor... (Key: {masked_key}){Colors.RESET}")
        
        try:
            response_data = model_instance.generate_content(
                system_instruction=config.SYSTEM_INSTRUCTION,
                prompt_text=full_prompt
            )
            
            if isinstance(response_data, str):
                raw_text = response_data; usage_info = {}; model_key_used = "unknown"
            else:
                raw_text = response_data["content"]; usage_info = response_data["usage"]; model_key_used = response_data["model_key"]

            # --- GÃœVENLÄ° PARSE Ä°ÅLEMÄ° (DÃœZELTÄ°LDÄ°) ---
            # ArtÄ±k clean_json_string direkt olarak dictionary veya None dÃ¶nÃ¼yor
            ai_response_plan = clean_json_string(raw_text)
            
            if ai_response_plan is None:
                print(f"{Colors.RED}âš ï¸ AI geÃ§ersiz format Ã¼retti. Tekrar deneniyor...{Colors.RESET}")
                # Ä°sterseniz burada 'continue' diyerek AI'ya tekrar sordurabilirsiniz
                # Ancak sonsuz dÃ¶ngÃ¼ye girmemesi iÃ§in ÅŸimdilik Ã§Ä±kÄ±ÅŸ yapÄ±yoruz veya kullanÄ±cÄ±ya soruyoruz.
                if input("Format bozuk. Tekrar denesin mi? (e/h): ").lower() == 'e':
                    continue
                else:
                    return

            # --- MALÄ°YET HESAPLAMA ---
            current_cost, total_cost = update_project_stats(working_dir, usage_info, model_key_used)
            print_cost_report(current_cost, total_cost, usage_info)
            break 

        except requests.exceptions.ConnectionError:
            print(f"\n{Colors.RED}ğŸ“¡ Ä°NTERNET BAÄLANTISI YOK!{Colors.RESET}")
            if input("Tekrar? (e/h): ").lower() != 'e': return
        
        except Exception as e:
            err_str = str(e)
            print(f"\n{Colors.RED}ğŸ’£ HATA: {e}{Colors.RESET}")
            if "429" in err_str:
                wait_time = extract_wait_time(err_str)
                print(f"{Colors.YELLOW}ğŸš¦ Kota doldu ({wait_time}s). [1] Bekle [2] Model SeÃ§ [3] Ä°ptal{Colors.RESET}")
                c = input("SeÃ§im: ")
                if c == "1":
                    time.sleep(wait_time); continue
                elif c == "2":
                    from model_selector import select_model_interactive
                    m = select_model_interactive()
                    if m: model_instance = m
                    continue
                else: return
            else:
                if input("Tekrar? (e/h): ").lower() != 'e': return

    # --- PLANLAMA ---
    explanation = ai_response_plan.get("aciklama", "AÃ§Ä±klama yok.")
    files_to_create = ai_response_plan.get("dosya_olustur", {})
    files_to_delete = ai_response_plan.get("dosya_sil", [])

    print(f"\n{Colors.MAGENTA}ğŸ¤– AI DÄ°YOR KÄ°:{Colors.RESET}")
    print(f"{Colors.CYAN}{explanation}{Colors.RESET}")
    
    print("\nğŸ“‹ PLANLANAN DEÄÄ°ÅÄ°KLÄ°KLER:")
    for path in files_to_create.keys(): print(f"   ğŸ“‚ OLUÅTUR/GÃœNCELLE: {path}")
    for path in files_to_delete: print(f"   ğŸ—‘ï¸  SÄ°LÄ°NECEK: {path}")

    if not files_to_create and not files_to_delete:
        print(f"{Colors.YELLOW}   (Ä°ÅŸlem yok){Colors.RESET}")
        log_conversation(working_dir, prompt_text, explanation, model_instance.MODEL_NAME, current_cost)
        return

    if is_dry_run:
        print(f"\n{Colors.YELLOW}ğŸ§ª DRY-RUN Bitti.{Colors.RESET}")
        return

    if input(f"\n{Colors.GREEN}OnaylÄ±yor musunuz? (e/h): {Colors.RESET}").lower() != 'e':
        print("âŒ Ä°ptal edildi.")
        return

    # --- UYGULAMA ---
    for rel_path in files_to_delete:
        if not is_safe_path(rel_path, working_dir): continue
        full_path = os.path.join(working_dir, rel_path)
        if os.path.exists(full_path):
            try:
                backup_file(full_path)
                os.remove(full_path)
                print(f"{Colors.RED}   ğŸ—‘ï¸  Silindi: {rel_path}{Colors.RESET}")
            except Exception as e:
                print(f"{Colors.RED}   âŒ Silinemedi: {rel_path} ({e}){Colors.RESET}")

    for rel_path, content in files_to_create.items():
        if not is_safe_path(rel_path, working_dir):
            print(f"{Colors.RED}ğŸš¨ Engellendi: {rel_path}{Colors.RESET}")
            continue
        full_path = os.path.join(working_dir, rel_path)
        os.makedirs(os.path.dirname(full_path), exist_ok=True)
        if os.path.exists(full_path): backup_file(full_path)
        with open(full_path, 'w', encoding='utf-8') as f: f.write(content)
        print(f"{Colors.GREEN}   âœ… YazÄ±ldÄ±: {rel_path}{Colors.RESET}")
        if memory: memory.index_files([rel_path])

    # Loglama (Maliyet parametresi eklendi)
    log_conversation(working_dir, prompt_text, explanation, model_instance.MODEL_NAME, current_cost)


if __name__ == "__main__":
    if len(sys.argv) < 2: sys.exit(1)
    
    raw_args = sys.argv[1:]
    is_dry_run = "--dry-run" in raw_args
    cleaned_args = [a for a in raw_args if a != "--dry-run" and a != "--verbose"]
    prompt = " ".join(cleaned_args)
    cwd = os.getcwd()
    
    from model_selector import select_model_interactive
    model = select_model_interactive()
    if model: main_process(prompt, model, cwd, is_dry_run=is_dry_run)
```

#### ğŸ“„ Dosya: `check_models.py`

```py
import os
import sys

# google-genai yÃ¼klÃ¼ mÃ¼ kontrol et
try:
    from google import genai
except ImportError:
    print("âŒ HATA: 'google-genai' kÃ¼tÃ¼phanesi bulunamadÄ±.")
    sys.exit(1)

api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    print("âŒ HATA: GOOGLE_API_KEY tanÄ±mlÄ± deÄŸil!")
    sys.exit(1)

print(f"ğŸ”‘ Anahtar ile baÄŸlanÄ±lÄ±yor... (Son 4 hane: {api_key[-4:]})")

try:
    client = genai.Client(api_key=api_key)
    print("\nğŸ“¡ --- HESABINIZDA AKTÄ°F OLAN MODELLER ---")
    
    count = 0
    # Modelleri Ã§ek ve listele
    # Pager Ã¼zerinden dÃ¶ner, listeye Ã§evirelim
    for m in client.models.list():
        # Sadece iÃ§erik Ã¼retebilen modelleri al
        if "generateContent" in m.supported_actions:
            # Ä°smi temizle (models/ Ã¶nekini at)
            clean_name = m.name.replace('models/', '')
            print(f"âœ… {clean_name}")
            count += 1
            
    if count == 0:
        print("\nâš ï¸ HATA: HiÃ§bir model bulunamadÄ±. API Key'inizin yetkilerini kontrol edin.")
    else:
        print("\nğŸ‘‰ Ä°PUCU: YukarÄ±daki âœ… ile baÅŸlayan isimlerden birini config.py dosyasÄ±na kopyalayÄ±n.")

except Exception as e:
    print(f"\nâŒ BAÄLANTI HATASI: {e}")
```

#### ğŸ“„ Dosya: `config.py`

```py
import os

# ==========================================
# ğŸ¨ RENK AYARLARI
# ==========================================
class Colors:
    GREEN = '\033[92m'
    RED = '\033[91m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    CYAN = '\033[96m'
    MAGENTA = '\033[95m'
    GREY = '\033[90m'
    BOLD = '\033[1m'
    RESET = '\033[0m'

# ==========================================
# âš™ï¸ SÄ°STEM VE DOSYA AYARLARI
# ==========================================
MAX_FILE_SIZE = 5 * 1024 * 1024
MAX_TOTAL_SIZE = 20 * 1024 * 1024
BACKUP_DIR = ".gassist_backups"
MAX_BACKUPS_PER_FILE = 5
MEMORY_DIR_NAME = ".coder_memory"
COLLECTION_NAME = "project_codebase"
EMBEDDING_MODEL = "all-MiniLM-L6-v2"
MAX_CONTEXT_RESULTS = 3
MAX_CONTEXT_CHARS = 12000
MAX_BACKUPS_PER_FILE = 10


# YENÄ°: Projelerin toplanacaÄŸÄ± ana klasÃ¶r
PROJECTS_DIR = "my_projects"

# ==========================================
# ğŸ’° MALÄ°YET VE KATMAN
# ==========================================
USER_TIER = 'free' 
PRICING_RATES = {
    "gemini-2.5-flash-lite": { "input": 0.075, "output": 0.30 },
    "gemini-2.5-flash": { "input": 0.10, "output": 0.40 },
    "llama-3.3-70b-versatile": { "input": 0.59, "output": 0.79 },
    "deepseek-chat": { "input": 0.14, "output": 0.28 },
    "Qwen/Qwen2.5-Coder-7B-Instruct": { "input": 0.0, "output": 0.0 }
}

# ==========================================
# ğŸ¤– MODEL AYARLARI
# ==========================================
MODEL_CONFIGS = {
    "gemini": {
        "env_var": "GOOGLE_API_KEY",
        "model_name": "gemini-2.5-flash-lite", 
        "display_name": "Google Gemini 2.5 Flash Lite",
    },
    "groq": {
        "env_var": "GROQ_API_KEY",
        "model_id": "llama-3.3-70b-versatile",
        "display_name": "Groq Llama 3.3 70B",
    },
    "deepseek": {
        "env_var": "DEEPSEEK_API_KEY",
        "model_id": "deepseek-chat",
        "display_name": "DeepSeek Chat",
    },
    "huggingface": {
        "env_var": "HUGGINGFACE_API_KEY",
        "model_id": "Qwen/Qwen2.5-Coder-7B-Instruct",
        "display_name": "Hugging Face Qwen",
    }
}

# ==========================================
# ğŸ§  YENÄ° AI SÄ°STEM TALÄ°MATI (AkÄ±llÄ± JSON Modu)
# ==========================================
SYSTEM_INSTRUCTION = (
    "Sen uzman bir yazÄ±lÄ±m mimarÄ± ve kodlama asistanÄ±sÄ±n. "
    "GÃ¶revin: Verilen talimatlara ve RAG hafÄ±zasÄ±ndan gelen baÄŸlama gÃ¶re projeyi yÃ¶netmektir.\n"
    "KURALLAR:\n"
    "1. YanÄ±tÄ±n SADECE ve SADECE geÃ§erli bir JSON objesi olmalÄ±dÄ±r.\n"
    "2. JSON formatÄ± ÅU ÅEKÄ°LDE OLMALIDIR:\n"
    "{\n"
    "  'aciklama': 'YaptÄ±ÄŸÄ±nÄ±z iÅŸlemin kÄ±sa bir Ã¶zeti ve nedeni (Ã–rn: HatalÄ± yolu dÃ¼zelttim)',\n"
    "  'dosya_olustur': {'dosya_yolu': 'icerik', 'dosya_yolu2': 'icerik'},\n"
    "  'dosya_sil': ['silinecek_dosya_yolu_1', 'silinecek_dosya_yolu_2']\n"
    "}\n"
    "3. EÄŸer silinecek dosya yoksa 'dosya_sil': [] gÃ¶nder.\n"
    "4. Asla Markdown (```json ... ```) kullanma, sadece saf JSON dÃ¶ndÃ¼r.\n"
    "5. TÃ¼rkÃ§e karakterleri UTF-8 olarak koru."
)
```

#### ğŸ“„ Dosya: `debug.py`

```py
import os
import sys
import chromadb
from pathlib import Path

# Config'den proje klasÃ¶r ismini Ã§ekelim
try:
    import config
    PROJECTS_DIR_NAME = config.PROJECTS_DIR
except ImportError:
    PROJECTS_DIR_NAME = "my_projects"

# Renkler
CYAN = '\033[96m'
GREEN = '\033[92m'
YELLOW = '\033[93m'
RED = '\033[91m'
RESET = '\033[0m'

def list_projects():
    # DÃœZELTME: ArtÄ±k ana dizine deÄŸil, my_projects klasÃ¶rÃ¼ne bakÄ±yoruz
    workspace = Path.cwd() / PROJECTS_DIR_NAME
    
    if not workspace.exists():
        print(f"{RED}Hata: {PROJECTS_DIR_NAME} klasÃ¶rÃ¼ bulunamadÄ±.{RESET}")
        return []

    projects = []
    for entry in workspace.iterdir():
        # .coder_memory klasÃ¶rÃ¼ olanlarÄ± proje say
        if entry.is_dir() and (entry / ".coder_memory").exists():
            projects.append(entry)
    return projects

def inspect_memory(project_path):
    memory_path = project_path / ".coder_memory"
    
    print(f"\n{CYAN}ğŸ§  VeritabanÄ± BaÄŸlanÄ±yor: {memory_path}{RESET}")
    
    try:
        # ChromaDB istemcisi
        client = chromadb.PersistentClient(path=str(memory_path))
        
        # Koleksiyonu bulmaya Ã§alÄ±ÅŸ
        try:
            # Config'deki ismi kullanÄ±yoruz
            collection = client.get_collection("project_codebase")
        except:
            print(f"{RED}âš ï¸ Koleksiyon bulunamadÄ±. VeritabanÄ± bozuk olabilir.{RESET}")
            return
        
        count = collection.count()
        print(f"{GREEN}ğŸ“Š Toplam KayÄ±tlÄ± ParÃ§a (Chunk): {count}{RESET}")
        
        if count == 0:
            print(f"{RED}âš ï¸ HafÄ±za boÅŸ! HenÃ¼z hiÃ§bir dosya indekslenmemiÅŸ.{RESET}")
            return

        print(f"\n{YELLOW}--- SON KAYDEDÄ°LEN 5 VERÄ° (Ã–rnek) ---{RESET}")
        
        # Ä°lk 5 veriyi Ã§ek
        data = collection.peek(limit=5)
        
        if not data['ids']:
            print("Veri Ã§ekilemedi.")
            return

        ids = data['ids']
        metadatas = data['metadatas']
        documents = data['documents']
        
        for i in range(len(ids)):
            doc_id = ids[i]
            meta = metadatas[i] if metadatas else "{}"
            content = documents[i] if documents else ""
            
            # Ä°Ã§erik Ã§ok uzunsa kÄ±saltarak gÃ¶ster
            preview = content[:150].replace('\n', ' ') + "..."
            
            print(f"[{i+1}] ID: {doc_id}")
            print(f"    Kaynak: {meta}")
            print(f"    Ä°Ã§erik: {preview}\n")
            
    except Exception as e:
        print(f"{RED}Hata: {e}{RESET}")
        print("VeritabanÄ± okunamadÄ±. C++ Build Tools eksik olabilir veya DB kilitli.")

if __name__ == "__main__":
    os.system('cls' if os.name == 'nt' else 'clear')
    print(f"ğŸ•µï¸  RAG HAFIZA MÃœFETTÄ°ÅÄ° (Hedef: {PROJECTS_DIR_NAME}/)")
    print("------------------------------------------------")
    
    projects = list_projects()
    
    if not projects:
        print(f"{YELLOW}HiÃ§ proje bulunamadÄ±.{RESET}")
        print(f"Not: Projelerinizin '{PROJECTS_DIR_NAME}' klasÃ¶rÃ¼nde olduÄŸundan emin olun.")
        sys.exit()
        
    for idx, p in enumerate(projects, 1):
        print(f"[{idx}] {p.name}")
        
    print("\n[Q] Ã‡Ä±kÄ±ÅŸ")
    choice = input("\nHangi projeyi inceleyelim? (No): ").strip()
    
    if choice.lower() == 'q':
        sys.exit()
        
    if choice.isdigit() and 1 <= int(choice) <= len(projects):
        inspect_memory(projects[int(choice)-1])
    else:
        print("GeÃ§ersiz seÃ§im.")
```

#### ğŸ“„ Dosya: `generate_docs.py`

```py
import os
import sys

# ==========================================
# âš™ï¸ AYARLAR VE FÄ°LTRELER
# ==========================================

# Sadece iÃ§eriÄŸi taranmayacak sistem klasÃ¶rleri
DIKKATE_ALINMAYACAK_DIZINLER = [
    '.git', '__pycache__', 'venv', '.venv', 'env', '.env', 'node_modules', 
    '.vscode', '.idea', 'dist', 'build', 'target', 'bin',
    '__macosx', '.ds_store', 'logs', 'site-packages', 'lib', 'include',
    '.gassist_backups', '.coder_memory'
]

# Ä°Ã§eriÄŸi dÃ¶kÃ¼lmeyecek ama varlÄ±ÄŸÄ± gÃ¶sterilecek "Ã–zel" klasÃ¶rler
OZEL_USER_KLASORLERI = ['my_projects']

# Ä°Ã§eriÄŸi dÃ¶kÃ¼me eklenecek kod uzantÄ±larÄ±
BELGELENECEK_KOD_UZANTILARI = [
    '.py', '.php', '.js', '.html', '.css', '.json', '.xml', '.yaml', '.yml', 
    '.sh', '.bash', '.c', '.cpp', '.h', '.hpp', '.java', '.go', '.rb', '.swift', 
    '.kt', '.ts', '.jsx', '.tsx', '.conf', '.ini', '.sql', '.md', '.txt'
]

# Ã‡Ä±ktÄ± dosyasÄ±nÄ±n adÄ±
CIKTI_DOSYASI = "proje_dokumu.md"

# ==========================================
# ğŸ› ï¸ FONKSÄ°YONLAR
# ==========================================

def dosya_icerigini_getir(yol):
    """Dosya iÃ§eriÄŸini okur ve Markdown kod bloÄŸu iÃ§inde dÃ¶ndÃ¼rÃ¼r."""
    try:
        with open(yol, 'r', encoding='utf-8') as f:
            icerik = f.read()
            
        uzanti = os.path.splitext(yol)[1].lstrip('.').lower()
        return f"\n```{(uzanti if uzanti else 'plaintext')}\n{icerik}\n```\n"
    except Exception as e:
        return f"\n> [OkunamadÄ±: {e}]\n"

def dizin_yapisi_getir(hedef_dizin):
    """Verilen yoldan baÅŸlayarak dizin yapÄ±sÄ±nÄ± dÃ¶ndÃ¼rÃ¼r."""
    yapÄ± = "### ğŸ“‚ Proje Dizin YapÄ±sÄ± ve Dosyalar\n\n"
    
    for kok, dizinler, dosyalar in os.walk(hedef_dizin):
        # Filtreleme: Gereksiz klasÃ¶rleri gezme
        dizinler[:] = [d for d in dizinler if d.lower() not in DIKKATE_ALINMAYACAK_DIZINLER]
        
        yol_parcalari = kok.lower().split(os.sep)
        if any(yasak in yol_parcalari for yasak in DIKKATE_ALINMAYACAK_DIZINLER):
            continue

        base_name = os.path.basename(kok)
        goreli_yol = os.path.relpath(kok, hedef_dizin)
        
        # AÄŸaÃ§ yapÄ±sÄ± baÅŸlÄ±ÄŸÄ±
        if goreli_yol == '.':
            seviye = 0
            yapÄ± += f"- **{os.path.basename(hedef_dizin)}/** (Proje KÃ¶kÃ¼)\n"
        else:
            seviye = goreli_yol.count(os.sep) + 1
            girinti = "  " * seviye
            
            # Ã–zel klasÃ¶r kontrolÃ¼ (my_projects gibi)
            if base_name in OZEL_USER_KLASORLERI:
                yapÄ± += f"{girinti}- **{base_name}/** (KullanÄ±cÄ± Projeleri - Ä°Ã§erik Gizli)\n"
                dizinler[:] = [] # AltÄ±na inme
                continue 
            else:
                yapÄ± += f"{girinti}- **{base_name}/**\n"

        girinti_dosya = "  " * (seviye + 1)
        
        # DOSYALARI LÄ°STELEME (Filtresiz)
        for dosya in sorted(dosyalar):
            # .git klasÃ¶rÃ¼ iÃ§indeki dosyalarÄ± hariÃ§ tut, gerisi gelsin
            if '.git' in yol_parcalari: continue
            
            yapÄ± += f"{girinti_dosya}- {dosya}\n"
                    
    return yapÄ±

def ana_fonksiyon():
    hedef_dizin = os.getcwd() 
    proje_adi = os.path.basename(hedef_dizin)
    
    dokum_metni = f"# ğŸ“ Proje DÃ¶kÃ¼mÃ¼: {proje_adi}\n\n"
    dokum_metni += f"Bu dÃ¶kÃ¼m, **{hedef_dizin}** dizini iÃ§in oluÅŸturulmuÅŸtur.\n"
    dokum_metni += "Not: `my_projects` klasÃ¶rÃ¼nÃ¼n iÃ§eriÄŸi gizlilik gereÄŸi hariÃ§ tutulmuÅŸtur.\n\n"
    
    print(f"1/3: '{proje_adi}' klasÃ¶r yapÄ±sÄ± taranÄ±yor...")
    dokum_metni += dizin_yapisi_getir(hedef_dizin)
    
    dokum_metni += "\n---\n"
    dokum_metni += "### ğŸ’» Kod Ä°Ã§eriÄŸi DÃ¶kÃ¼mÃ¼\n\n"
    
    print("2/3: Kod iÃ§erikleri toplanÄ±yor...")
    
    dosya_sayisi = 0
    for kok, dizinler, dosyalar in os.walk(hedef_dizin):
        dizinler[:] = [d for d in dizinler if d.lower() not in DIKKATE_ALINMAYACAK_DIZINLER]
        
        if os.path.basename(kok) in OZEL_USER_KLASORLERI:
            dizinler[:] = []
            continue

        yol_parcalari = kok.lower().split(os.sep)
        if any(yasak in yol_parcalari for yasak in DIKKATE_ALINMAYACAK_DIZINLER): continue

        for dosya in sorted(dosyalar):
            dosya_yolu = os.path.join(kok, dosya)
            
            # KENDÄ°SÄ°NÄ° VE Ã‡IKTI DOSYASINI OKUMASIN (Ä°Ã§erik DÃ¶kÃ¼mÃ¼nde)
            if dosya == CIKTI_DOSYASI: continue
            
            uzanti = os.path.splitext(dosya)[1].lower()

            if uzanti in BELGELENECEK_KOD_UZANTILARI:
                goreli_yol = os.path.relpath(dosya_yolu, hedef_dizin)
                dokum_metni += f"\n#### ğŸ“„ Dosya: `{goreli_yol}`\n"
                dokum_metni += dosya_icerigini_getir(dosya_yolu)
                dosya_sayisi += 1
            
    print(f"3/3: '{CIKTI_DOSYASI}' dosyasÄ±na kayÄ±t yapÄ±lÄ±yor...")
    try:
        cikti_yolu = os.path.join(hedef_dizin, CIKTI_DOSYASI)
        with open(cikti_yolu, 'w', encoding='utf-8') as f:
            f.write(dokum_metni)
        print(f"\nâœ… Ä°ÅŸlem BaÅŸarÄ±lÄ±! Toplam {dosya_sayisi} dosya belgelendi.")
    except Exception as e:
        print(f"\nâŒ Hata: {e}")
        
if __name__ == "__main__":
    ana_fonksiyon()
```

#### ğŸ“„ Dosya: `launcher.py`

```py
import os
import sys
import platform
import subprocess
import re
import json
import shutil
from pathlib import Path
from datetime import datetime

# Renk kodlarÄ±
GREEN = '\033[92m'
CYAN = '\033[96m'
YELLOW = '\033[93m'
RED = '\033[91m'
GREY = '\033[90m'
MAGENTA = '\033[95m'
RESET = '\033[0m'

# Config'den proje klasÃ¶rÃ¼nÃ¼ al
try:
    import config
    PROJECTS_ROOT = Path.cwd() / config.PROJECTS_DIR
except ImportError:
    # Config yoksa varsayÄ±lan
    PROJECTS_ROOT = Path.cwd() / "my_projects"

try:
    from core.memory import MemoryManager
except ImportError:
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    from core.memory import MemoryManager

def clear_screen():
    os.system('cls' if os.name == 'nt' else 'clear')

def ensure_workspace():
    """Ã‡alÄ±ÅŸma alanÄ± klasÃ¶rÃ¼nÃ¼ oluÅŸturur."""
    if not PROJECTS_ROOT.exists():
        os.makedirs(PROJECTS_ROOT)

def slugify(text):
    text = text.lower()
    text = text.replace('Ä±', 'i').replace('ÄŸ', 'g').replace('Ã¼', 'u').replace('ÅŸ', 's').replace('Ã¶', 'o').replace('Ã§', 'c')
    text = re.sub(r'[^a-z0-9]', '-', text)
    text = re.sub(r'-+', '-', text)
    return text.strip('-')

def get_projects():
    projects = []
    ensure_workspace()
    for entry in PROJECTS_ROOT.iterdir():
        if entry.is_dir() and (entry / ".coder_memory").exists():
            projects.append(entry)
    return projects

def get_project_stats(project_path: Path):
    stats_file = project_path / ".project_stats.json"
    total_cost = 0.0
    last_updated = "-"
    if stats_file.exists():
        try:
            with open(stats_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                total_cost = data.get("total_cost", 0.0)
                last_updated = data.get("last_updated", "-")
        except: pass
    return total_cost, last_updated

def export_project(project_path: Path):
    """Projeyi taÅŸÄ±nabilir ZIP formatÄ±na getirir."""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M')
    zip_name = f"{project_path.name}_BACKUP_{timestamp}"
    zip_path = PROJECTS_ROOT / zip_name
    
    print(f"\n{CYAN}ğŸ“¦ Proje paketleniyor: {project_path.name}...{RESET}")
    try:
        shutil.make_archive(str(zip_path), 'zip', project_path)
        print(f"{GREEN}âœ… Yedek OluÅŸturuldu: {zip_path}.zip{RESET}")
        print(f"{GREY}   (Bu dosyayÄ± USB'ye atÄ±p baÅŸka bilgisayara taÅŸÄ±yabilirsiniz){RESET}")
        input(f"\nDevam etmek iÃ§in Enter...")
    except Exception as e:
        print(f"{RED}Paketleme hatasÄ±: {e}{RESET}")
        input()

def create_new_project_wizard():
    print(f"\n{CYAN}âœ¨ YENÄ° PROJE OLUÅTUR{RESET}")
    while True:
        p_name = input(f"{YELLOW}1. Proje AdÄ±: {RESET}").strip()
        if p_name: break
    
    print(f"{CYAN}2. AÃ§Ä±klama{RESET}")
    p_desc = input(f"{YELLOW}   Detay: {RESET}").strip()
    if not p_desc: p_desc = f"{p_name} projesi."

    suggested_folder = slugify(p_name)
    p_folder = input(f"{YELLOW}3. KlasÃ¶r AdÄ± [{suggested_folder}]: {RESET}").strip()
    if not p_folder: p_folder = suggested_folder
        
    # ARTIK ANA DÄ°ZÄ°NE DEÄÄ°L, MY_PROJECTS ALTINA KURUYORUZ
    target_path = PROJECTS_ROOT / p_folder
    
    if target_path.exists():
        print(f"\n{RED}âŒ Hata: Bu isimde bir proje zaten var!{RESET}")
        return None

    try:
        os.makedirs(target_path)
        print(f"{CYAN}ğŸ§  HafÄ±za kuruluyor...{RESET}")
        memory = MemoryManager(project_root=str(target_path))
        
        readme_content = f"# {p_name}\n\n## Proje HakkÄ±nda\n{p_desc}\n\nBu proje Coder-Asistan ile oluÅŸturuldu."
        with open(target_path / "README.md", "w", encoding="utf-8") as f:
            f.write(readme_content)
            
        memory.collection.upsert(
            documents=[f"PROJE TANIMI: {p_desc}"],
            embeddings=memory.embedder.encode([p_desc]).tolist(),
            metadatas=[{"source": "project_init"}],
            ids=["project_description"]
        )
        print(f"{GREEN}âœ… Proje HazÄ±r!{RESET}")
        return target_path
    except Exception as e:
        print(f"{RED}Hata: {e}{RESET}")
        return None

def print_chat_history(project_path: Path):
    log_file = project_path / ".chat_history.log"
    if log_file.exists():
        print(f"\n{GREY}ğŸ“œ GEÃ‡MÄ°Å KAYITLAR{RESET}")
        try:
            with open(log_file, 'r', encoding='utf-8') as f:
                content = f.read()
                content = content.replace("ğŸ‘¤ USER:", f"{YELLOW}ğŸ‘¤ USER:{RESET}")
                content = content.replace("ğŸ¤– AI:", f"{GREEN}ğŸ¤– AI:{RESET}")
                content = content.replace("ğŸ’° MALÄ°YET:", f"{MAGENTA}ğŸ’° MALÄ°YET:{RESET}")
                print(content)
        except: pass
    else:
        print(f"\n{GREY}(HenÃ¼z geÃ§miÅŸ yok){RESET}")

def launch_assistant(project_path):
    clear_screen()
    total_cost, last_upd = get_project_stats(project_path)
    
    print(f"{GREEN}ğŸ“‚ PROJE: {project_path.name}{RESET}")
    print(f"{MAGENTA}ğŸ’° TOPLAM: ${total_cost:.5f}{RESET} {GREY}(Son: {last_upd}){RESET}")
    
    readme = project_path / "README.md"
    if readme.exists():
         with open(readme, 'r', encoding='utf-8') as f:
             print(f"{CYAN}â„¹ï¸  {f.readline().strip().replace('# ', '')}{RESET}")

    print_chat_history(project_path)
    print(f"{CYAN}----------------------------------------{RESET}")
    print(f"{GREY}(Sohbet geÃ§miÅŸi yukarÄ±da kalacaktÄ±r. Ã‡Ä±kÄ±ÅŸ iÃ§in 'b' yazÄ±n){RESET}\n")

    while True:
        task = input(f"{YELLOW}User (Siz) > {RESET}").strip()
        if task.lower() == 'b': return
        if not task: continue
            
        # Assistant scripti bir Ã¼st dizinde (ana kÃ¶k dizinde)
        assistant_script = Path(__file__).parent / "assistant.py"
        cmd = [sys.executable, str(assistant_script), task]
        
        print(f"{CYAN}----------------------------------------{RESET}")
        try:
            subprocess.run(cmd, cwd=str(project_path))
            print(f"{CYAN}----------------------------------------{RESET}")
        except Exception as e:
            print(f"{RED}Hata: {e}{RESET}")

def main():
    ensure_workspace()
    
    while True:
        clear_screen()
        projects = get_projects()
        
        if not projects:
            create_new_project_wizard()
            continue

        print(f"{GREEN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        print(f"â•‘   ğŸš€ CODER-ASISTAN (Projeler: {len(projects)})      â•‘")
        print(f"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{RESET}")
        
        for idx, proj in enumerate(projects, 1):
            cost, _ = get_project_stats(proj)
            print(f"[{idx}] {proj.name:<20} {MAGENTA}${cost:.4f}{RESET}")
            
        print(f"\n[{GREEN}N{RESET}] âœ¨ Yeni Proje")
        print(f"[{CYAN}E{RESET}] ğŸ“¦ Projeyi Paketle (Zip/Yedek)")
        print(f"[{RED}Q{RESET}] ğŸšª Ã‡Ä±kÄ±ÅŸ")
        
        choice = input(f"\n{YELLOW}SeÃ§im: {RESET}").strip().upper()
        
        if choice == 'Q': sys.exit()
        elif choice == 'N':
            new_proj = create_new_project_wizard()
            if new_proj: launch_assistant(new_proj)
        elif choice == 'E':
            try:
                p_idx = int(input("Paketlenecek proje numarasÄ±: "))
                if 1 <= p_idx <= len(projects):
                    export_project(projects[p_idx-1])
            except ValueError: pass
        elif choice.isdigit():
            idx = int(choice)
            if 1 <= idx <= len(projects):
                launch_assistant(projects[idx-1])

if __name__ == "__main__":
    main()
```

#### ğŸ“„ Dosya: `migrate_projects.py`

```py
import os
import shutil
from pathlib import Path

# Hedef
TARGET_DIR = Path("my_projects")
if not TARGET_DIR.exists():
    os.makedirs(TARGET_DIR)

print("ğŸšš Proje TaÅŸÄ±ma Ä°ÅŸlemi BaÅŸlÄ±yor...")

# Mevcut dizindeki klasÃ¶rleri tara
for entry in Path.cwd().iterdir():
    # Kendi dizinimizdeki klasÃ¶rler (my_projects hariÃ§)
    if entry.is_dir() and entry.name != "my_projects" and entry.name != "core" and entry.name != "venv" and not entry.name.startswith("."):
        
        # EÄŸer iÃ§inde .coder_memory varsa bu bir projedir!
        if (entry / ".coder_memory").exists():
            print(f"ğŸ“¦ Bulundu ve TaÅŸÄ±nÄ±yor: {entry.name}")
            try:
                shutil.move(str(entry), str(TARGET_DIR / entry.name))
                print(f"   âœ… TaÅŸÄ±ndÄ±.")
            except Exception as e:
                print(f"   âŒ Hata: {e}")

print("\nğŸ Ä°ÅŸlem Tamam. ArtÄ±k launcher.py'yi Ã§alÄ±ÅŸtÄ±rabilirsiniz.")
```

#### ğŸ“„ Dosya: `model_selector.py`

```py
# model_selector.py
import os
from config import Colors, MODEL_CONFIGS

def check_api_key(env_var):
    """Ortam deÄŸiÅŸkeninde API anahtarÄ± var mÄ± kontrol eder."""
    key = os.getenv(env_var)
    return key is not None and len(key) > 0

def get_available_models():
    """Sistemdeki kullanÄ±labilir modelleri dinamik olarak tarar."""
    available = {}
    
    # 1. Gemini KontrolÃ¼
    gemini_conf = MODEL_CONFIGS["gemini"]
    if check_api_key(gemini_conf["env_var"]):
        try:
            from core.gemini import GeminiModel
            available["1"] = {
                "class": GeminiModel,
                "name": gemini_conf["display_name"],
                "status": f"{Colors.GREEN}âœ… HazÄ±r{Colors.RESET}"
            }
        except ImportError:
            available["1"] = {"status": f"{Colors.RED}âŒ KÃ¼tÃ¼phane eksik (google-genai){Colors.RESET}"}
    else:
        available["1"] = {
            "name": gemini_conf["display_name"],
            "status": f"{Colors.RED}âŒ API Key Eksik ({gemini_conf['env_var']}){Colors.RESET}"
        }

    # 2. Hugging Face KontrolÃ¼
    hf_conf = MODEL_CONFIGS["huggingface"]
    if check_api_key(hf_conf["env_var"]):
        try:
            from core.huggingface import HuggingFaceModel
            available["2"] = {
                "class": HuggingFaceModel,
                "name": hf_conf["display_name"],
                "status": f"{Colors.GREEN}âœ… HazÄ±r{Colors.RESET}"
            }
        except ImportError:
             available["2"] = {"status": f"{Colors.RED}âŒ KÃ¼tÃ¼phane eksik (requests){Colors.RESET}"}
    else:
        available["2"] = {
            "name": hf_conf["display_name"],
            "status": f"{Colors.RED}âŒ API Key Eksik ({hf_conf['env_var']}){Colors.RESET}"
        }

    return available

def select_model_interactive():
    """KullanÄ±cÄ±ya interaktif seÃ§im menÃ¼sÃ¼ sunar."""
    available = get_available_models()
    
    print(f"\n{Colors.BLUE}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print(f"â•‘       ğŸ¤–  AI MODEL SEÃ‡Ä°M EKRANI        â•‘")
    print(f"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{Colors.RESET}\n")

    ready_models = {}
    
    for key, info in available.items():
        # EÄŸer 'class' anahtarÄ± varsa model Ã§alÄ±ÅŸtÄ±rÄ±labilir demektir
        if "class" in info:
            ready_models[key] = info["class"]
            print(f"  [{key}] {info['name']}  {info['status']}")
        else:
            print(f"  [{key}] {info.get('name', 'Bilinmeyen')}  {info['status']}")

    if not ready_models:
        print(f"\n{Colors.RED}âš ï¸  HÄ°Ã‡BÄ°R MODEL KULLANILABÄ°LÄ°R DURUMDA DEÄÄ°L!{Colors.RESET}")
        print(f"{Colors.YELLOW}LÃ¼tfen .bashrc dosyasÄ±na API anahtarlarÄ±nÄ±zÄ± ekleyin.{Colors.RESET}")
        return None

    # VarsayÄ±lan olarak ilk hazÄ±r modeli seÃ§
    default_key = list(ready_models.keys())[0]
    
    print(f"\n{Colors.CYAN}VarsayÄ±lan Model: {available[default_key]['name']} (Enter'a bas){Colors.RESET}")
    choice = input(f"{Colors.YELLOW}SeÃ§iminiz [1/2]: {Colors.RESET}").strip()
    
    if not choice:
        choice = default_key
        
    if choice in ready_models:
        try:
            return ready_models[choice]()
        except Exception as e:
            print(f"{Colors.RED}Model baÅŸlatÄ±lÄ±rken hata oluÅŸtu: {e}{Colors.RESET}")
            return None
    else:
        print(f"{Colors.RED}GeÃ§ersiz seÃ§im.{Colors.RESET}")
        return None
```

#### ğŸ“„ Dosya: `readme.md`

```md
# ğŸš€ Coder-Asistan
### HafÄ±zalÄ±, GÃ¼venli ve Proje OdaklÄ± AI Kodlama StÃ¼dyosu

![Python](https://img.shields.io/badge/python-3.10%2B-blue)
![License](https://img.shields.io/badge/license-MIT-green)
![Status](https://img.shields.io/badge/status-active-success)

**Coder-Asistan**, klasik "soru sor â€“ cevap al" botlarÄ±ndan farklÄ± olarak, projelerinizi yÃ¶neten, baÄŸlamÄ± hatÄ±rlayan ve kodu **kontrollÃ¼ ÅŸekilde** deÄŸiÅŸtiren **terminal tabanlÄ± bir AI geliÅŸtirme ortamÄ±dÄ±r.**

Her proje iÃ§in ayrÄ± bir hafÄ±za oluÅŸturur (RAG). Bir projede Ã¶ÄŸrendiÄŸini diÄŸerine taÅŸÄ±maz. Ne yaptÄ±ÄŸÄ±nÄ± Ã¶nce planlar, sonra siz onaylarsanÄ±z uygular.

> **KÄ±saca:** Bu bir bot deÄŸil, **AI destekli bir geliÅŸtirme Ã§alÄ±ÅŸma alanÄ±**.

---

## ğŸ¯ Temel Ã–zellikler

* **ğŸ­ Proje FabrikasÄ± (`launcher.py`):** TÃ¼m projeleri tek merkezden yÃ¶netin.
* **ğŸ§  Ä°zole HafÄ±za:** Her projenin kendi `.coder_memory` klasÃ¶rÃ¼ vardÄ±r. AI, projenizdeki dosyalarÄ± okur ve hatÄ±rlar.
* **ğŸ›¡ï¸ GÃ¼venli Mod:** KodlarÄ± doÄŸrudan yazmaz; Ã¶nce plan sunar, onaylarsanÄ±z iÅŸler.
* **ğŸ’° Maliyet Takibi:** Token baÅŸÄ±na harcamayÄ± kuruÅŸu kuruÅŸuna raporlar.
* **ğŸ”Œ Model Ã–zgÃ¼rlÃ¼ÄŸÃ¼:** Google Gemini, Llama 3 (Groq), DeepSeek veya Hugging Face.

---

## ğŸ“¦ Kurulum (2 Dakikada HazÄ±r)

### 1ï¸âƒ£ Projeyi Ä°ndirin
```bash
git clone [https://github.com/cetincevizcetoli/coder-asistan.git](https://github.com/cetincevizcetoli/coder-asistan.git)
cd coder-asistan
```

### 2ï¸âƒ£ Sanal Ortam OluÅŸturun (Ã–NEMLÄ°)

**ğŸªŸ Windows:**
```cmd
python -m venv venv
venv\Scripts\activate
```

**ğŸ§ Linux / macOS:**
```bash
python3 -m venv venv
source venv/bin/activate
```
*(Terminal satÄ±rÄ±nÄ±n baÅŸÄ±nda `(venv)` yazÄ±sÄ±nÄ± gÃ¶rmelisiniz.)*

### 3ï¸âƒ£ Paketleri YÃ¼kleyin
```bash
pip install -r requirements.txt
```

---

## ğŸ”‘ API AnahtarÄ± AyarlarÄ±

Coder-Asistan bir beyne ihtiyaÃ§ duyar. **Google Gemini (Ãœcretsiz)** Ã¶nerilir.

1. [Google AI Studio](https://aistudio.google.com/app/apikey) adresinden Key alÄ±n.
2. BilgisayarÄ±nÄ±za kaydedin:

**ğŸªŸ Windows (KalÄ±cÄ±):**
```cmd
setx GOOGLE_API_KEY "API_KEY_BURAYA_YAPISTIR"
```
*(Komuttan sonra terminali kapatÄ±p yeniden aÃ§Ä±n!)*

**ğŸ§ Linux / macOS:**
```bash
echo 'export GOOGLE_API_KEY="API_KEY_BURAYA"' >> ~/.bashrc
source ~/.bashrc
```

---

## â–¶ï¸ NasÄ±l KullanÄ±lÄ±r? (Ana Kumanda)

TÃ¼m sistemi yÃ¶netmek iÃ§in tek bir komut yeterlidir:

```bash
python launcher.py
```

KarÅŸÄ±nÄ±za gelen menÃ¼den:
* **[N]** ile yeni proje oluÅŸturabilir,
* **[1-9]** ile mevcut projelerinize girip AI ile Ã§alÄ±ÅŸmaya baÅŸlayabilirsiniz.
* **[E]** ile projelerinizi ZIP olarak yedekleyebilirsiniz.

---

## ğŸ› ï¸ Ä°sviÃ§re Ã‡akÄ±sÄ±: YardÄ±mcÄ± AraÃ§lar

Bu projede sadece kod yazan bir asistan yok, iÅŸinizi kolaylaÅŸtÄ±racak bir dizi **profesyonel araÃ§** bulunur. Ä°ÅŸte alet Ã§antanÄ±z:

### 1. ğŸ•µï¸â€â™‚ï¸ HafÄ±za MÃ¼fettiÅŸi (`debug.py`)
AI'nÄ±n projeniz hakkÄ±nda ne bildiÄŸini merak mÄ± ediyorsunuz? VektÃ¶r veritabanÄ±nÄ±n iÃ§ine girip kaydedilen kod parÃ§alarÄ±nÄ± okumanÄ±zÄ± saÄŸlar.
```bash
python debug.py
```
* **Ne zaman kullanÄ±lÄ±r?** AI, kodunuzu hatÄ±rlamÄ±yorsa veya yanlÄ±ÅŸ cevap veriyorsa hafÄ±zayÄ± kontrol etmek iÃ§in.

### 2. ğŸšš Proje Nakliyecisi (`migrate_projects.py`)
Eski sÃ¼rÃ¼mden kalma veya yanlÄ±ÅŸlÄ±kla ana dizine kopyaladÄ±ÄŸÄ±nÄ±z projeleri bulur ve otomatik olarak yeni sisteme (`my_projects` klasÃ¶rÃ¼ne) taÅŸÄ±r.
```bash
python migrate_projects.py
```
* **Ne zaman kullanÄ±lÄ±r?** KlasÃ¶rde projeniz var ama Launcher listesinde gÃ¶rÃ¼nmÃ¼yorsa.

### 3. ğŸ©º Sistem Doktoru (`system_audit.py`)
Projelerinizin saÄŸlÄ±k kontrolÃ¼nÃ¼ yapar. Log dosyalarÄ± dolu mu? VeritabanÄ± bÃ¼tÃ¼nlÃ¼ÄŸÃ¼ (integrity) saÄŸlam mÄ±? Hepsini raporlar.
```bash
python system_audit.py
```
* **Ne zaman kullanÄ±lÄ±r?** Sistemsel bir hatadan ÅŸÃ¼pheleniyorsanÄ±z veya veritabanÄ± bozulduysa.

### 4. ğŸ“ Proje Katibi (`generate_docs.py`)
TÃ¼m projenizin kodlarÄ±nÄ± okur ve tek bir Markdown dosyasÄ±nda (`proje_dokumu.md`) birleÅŸtirir.
```bash
python generate_docs.py
```
* **Ne zaman kullanÄ±lÄ±r?** Projenin tamamÄ±nÄ± ChatGPT/Claude gibi baÅŸka bir AI'ya atÄ±p "Bunu analiz et" demek istediÄŸinizde.

### 5. ğŸ“¡ Model KontrolcÃ¼sÃ¼ (`check_models.py`)
Google hesabÄ±nÄ±zda tanÄ±mlÄ± ve eriÅŸilebilir olan Gemini modellerini listeler.
```bash
python check_models.py
```
* **Ne zaman kullanÄ±lÄ±r?** "Hangi modelleri kullanabilirim?" diye merak ettiÄŸinizde.

---

## ğŸ§ª GeliÅŸmiÅŸ Parametreler

Projeye girdikten sonra (veya `assistant.py`'yi manuel kullanÄ±rken) ÅŸu modlarÄ± kullanabilirsiniz:

* **`--dry-run` (Prova Modu):**
  AI kodlarÄ± yazar, planÄ± gÃ¶sterir ama **dosyaya kaydetmez.**
  ```bash
  python assistant.py "Ana sayfayÄ± deÄŸiÅŸtir" --dry-run
  ```

* **`--verbose` (Geveze Mod):**
  Arka planda dÃ¶nen ham JSON verisini ve dÃ¼ÅŸÃ¼nce sÃ¼recini gÃ¶sterir. Hata ayÄ±klamak iÃ§in idealdir.
  ```bash
  python assistant.py "Hata bul" --verbose
  ```

---

## ğŸ—ï¸ Proje Mimarisi

```text
coder-asistan/
â”œâ”€ launcher.py          # ğŸ® ANA KUMANDA (BaÅŸlatÄ±cÄ±)
â”œâ”€ assistant.py         # ğŸ§  Ä°ÅŸlem Motoru
â”œâ”€ my_projects/         # ğŸ“‚ PROJE FABRÄ°KASI
â”‚  â””â”€ odev-1/           # ğŸ”’ Ä°zole Proje AlanÄ±
â”‚     â”œâ”€ .coder_memory/ # ğŸ§  Projeye Ã¶zel hafÄ±za
â”‚     â””â”€ src/           # KodlarÄ±nÄ±z
â”œâ”€ debug.py             # ğŸ•µï¸â€â™‚ï¸ HafÄ±za MÃ¼fettiÅŸi
â”œâ”€ system_audit.py      # ğŸ©º Sistem Doktoru
â”œâ”€ migrate_projects.py  # ğŸšš TaÅŸÄ±yÄ±cÄ±
â””â”€ requirements.txt
```

---

## ğŸ’¡ Ä°puÃ§larÄ± ve PÃ¼f NoktalarÄ±

* **ğŸ—‘ï¸ Proje Silme:** Bir projeyi silmek iÃ§in Launcher'da bir komut yoktur. `my_projects` klasÃ¶rÃ¼ne gidip ilgili proje klasÃ¶rÃ¼nÃ¼ **elle silmeniz** yeterlidir.
* **ğŸ§  HafÄ±za SÄ±fÄ±rlama:** AI eski kodlarÄ± hatÄ±rlamakta Ä±srar ediyorsa veya kafasÄ± karÄ±ÅŸtÄ±ysa; proje klasÃ¶rÃ¼nÃ¼zdeki `.coder_memory` klasÃ¶rÃ¼nÃ¼ silin. Coder-Asistan bir sonraki aÃ§Ä±lÄ±ÅŸta dosyalarÄ± tarayÄ±p hafÄ±zayÄ± sÄ±fÄ±rdan kuracaktÄ±r.
* **âš™ï¸ Ä°nce Ayarlar:** Dosya boyutu sÄ±nÄ±rlarÄ±nÄ± veya maliyet hesaplama yÃ¶ntemini deÄŸiÅŸtirmek isterseniz `config.py` dosyasÄ±nÄ± dÃ¼zenleyebilirsiniz.

---
## ğŸ¤ KatkÄ±da Bulunma

Pull request'ler kabul edilir! BÃ¼yÃ¼k deÄŸiÅŸiklikler iÃ§in Ã¶nce bir Issue aÃ§arak tartÄ±ÅŸalÄ±m.

> ğŸ—ï¸ **GeliÅŸtirici Notu:** Bu projenin iÃ§ yapÄ±sÄ±nÄ±, veri akÄ±ÅŸÄ±nÄ± ve teknik detaylarÄ±nÄ± derinlemesine incelemek iÃ§in lÃ¼tfen **[MÄ°MARÄ° VE TEKNÄ°K KILAVUZ (ARCHITECTURE.md)](ARCHITECTURE.md)** dosyasÄ±nÄ± okuyunuz.
---
## ğŸ‘¤ GeliÅŸtirici

**Ahmet Ã‡etin**
* **GitHub:** [github.com/cetincevizcetoli](https://github.com/cetincevizcetoli)
* **Web:** [yapanzeka.acetin.com.tr](https://yapanzeka.acetin.com.tr)

> *"KarmaÅŸÄ±k kodlarÄ±, kontrollÃ¼ araÃ§larla yÃ¶netin."*
```

#### ğŸ“„ Dosya: `requirements.txt`

```txt
google-genai
requests
# --- RAG ve HafÄ±za ---
chromadb>=0.4.0
sentence-transformers>=2.2.0
torch>=2.0.0
# --- YardÄ±mcÄ±lar ---
tqdm  # Ä°ndeksleme sÄ±rasÄ±nda progress bar iÃ§in (opsiyonel ama iyi pratik)
```

#### ğŸ“„ Dosya: `system_audit.py`

```py
import os
import sys
import sqlite3
from pathlib import Path

# Config dosyasÄ±ndan proje klasÃ¶rÃ¼nÃ¼ Ã¶ÄŸrenelim
try:
    import config
    PROJECTS_DIR_NAME = config.PROJECTS_DIR
except ImportError:
    PROJECTS_DIR_NAME = "my_projects"

# Renkler
GREEN = '\033[92m'
RED = '\033[91m'
YELLOW = '\033[93m'
RESET = '\033[0m'
CYAN = '\033[96m'

def check_file_exists(path, description):
    if os.path.exists(path):
        size = os.path.getsize(path)
        print(f"{GREEN}âœ… {description} Mevcut ({size} bytes){RESET}")
        return True
    else:
        print(f"{RED}âŒ {description} BULUNAMADI! ({path}){RESET}")
        return False

def audit_log_file(project_path):
    log_path = project_path / ".chat_history.log"
    print(f"\n--- ğŸ“œ LOG DOSYASI KONTROLÃœ ({log_path.name}) ---")
    
    if check_file_exists(log_path, "Log DosyasÄ±"):
        try:
            with open(log_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                print(f"   ğŸ“„ Toplam SatÄ±r: {len(lines)}")
                if len(lines) > 0:
                    print(f"   ğŸ” Son KayÄ±t: {lines[-2].strip() if len(lines) > 1 else lines[0].strip()}")
                else:
                    print(f"{YELLOW}   âš ï¸ Dosya var ama iÃ§i boÅŸ.{RESET}")
        except Exception as e:
            print(f"{RED}   âŒ Dosya okuma hatasÄ±: {e}{RESET}")

def audit_vector_db(project_path):
    db_path = project_path / ".coder_memory"
    sqlite_file = db_path / "chroma.sqlite3"
    
    print(f"\n--- ğŸ§  VEKTÃ–R VERÄ°TABANI KONTROLÃœ ---")
    
    if not os.path.exists(db_path):
        print(f"{RED}âŒ .coder_memory klasÃ¶rÃ¼ yok (HafÄ±zasÄ±z Proje).{RESET}")
        return

    if check_file_exists(sqlite_file, "ChromaDB SQLite DosyasÄ±"):
        try:
            # ChromaDB kÃ¼tÃ¼phanesini kullanmadan direkt SQL ile bÃ¼tÃ¼nlÃ¼k testi
            conn = sqlite3.connect(sqlite_file)
            cursor = conn.cursor()
            
            # TablolarÄ± say
            cursor.execute("SELECT count(*) FROM sqlite_master WHERE type='table';")
            tables = cursor.fetchone()[0]
            print(f"   ğŸ“Š Tablo SayÄ±sÄ±: {tables}")
            
            # Embedding sayÄ±sÄ±nÄ± bulmaya Ã§alÄ±ÅŸ
            try:
                # Chroma versiyonuna gÃ¶re tablo adÄ± deÄŸiÅŸebilir, genelde 'embeddings'
                cursor.execute("SELECT count(*) FROM embeddings;")
                count = cursor.fetchone()[0]
                print(f"   ğŸ§¬ Ä°ndekslenmiÅŸ VektÃ¶r SayÄ±sÄ±: {GREEN}{count}{RESET}")
            except:
                print(f"{YELLOW}   âš ï¸ 'embeddings' tablosu direkt okunamadÄ± (Versiyon farkÄ± olabilir).{RESET}")
                
            conn.close()
            print(f"{GREEN}   âœ… VeritabanÄ± bÃ¼tÃ¼nlÃ¼ÄŸÃ¼ (Integrity) saÄŸlam.{RESET}")
            
        except Exception as e:
            print(f"{RED}   âŒ VeritabanÄ± bozuk veya okunamÄ±yor: {e}{RESET}")

def main():
    # DÃœZELTME: ArtÄ±k kÃ¶k dizine deÄŸil, my_projects iÃ§ine bakÄ±yoruz
    workspace = Path.cwd() / PROJECTS_DIR_NAME
    
    if not workspace.exists():
        print(f"{RED}Hata: '{PROJECTS_DIR_NAME}' klasÃ¶rÃ¼ bulunamadÄ±.{RESET}")
        return

    # Projeleri bul (iÃ§inde .coder_memory olan klasÃ¶rler)
    projects = [d for d in workspace.iterdir() if d.is_dir() and (d / ".coder_memory").exists()]
    
    print(f"{CYAN}ğŸ” SÄ°STEM DENETÃ‡Ä°SÄ° BAÅLATILDI{RESET}")
    print(f"ğŸ“‚ Hedef Dizin: {workspace}")
    
    if not projects:
        print(f"{RED}Test edilecek proje bulunamadÄ±.{RESET}")
        return

    print(f"âœ… {len(projects)} adet proje tespit edildi.")
    
    for proj in projects:
        print(f"\n{YELLOW}========================================{RESET}")
        print(f"ğŸ“‚ PROJE DENETLENÄ°YOR: {proj.name}")
        print(f"{YELLOW}========================================{RESET}")
        
        audit_log_file(proj)
        audit_vector_db(proj)

if __name__ == "__main__":
    main()
```

#### ğŸ“„ Dosya: `core\base.py`

```py
# core/base.py: Ortak ArayÃ¼z ve Hata TanÄ±mlarÄ±

class ModelAPIError(Exception):
    """API baÄŸlantÄ±/kota hatalarÄ± iÃ§in genel hata sÄ±nÄ±fÄ±."""
    pass

class BaseModel:
    """TÃ¼m model sÄ±nÄ±flarÄ±nÄ±n miras alacaÄŸÄ± soyut sÄ±nÄ±f."""
    MODEL_NAME = "Temel Model"

    def __init__(self):
        # API anahtarÄ±nÄ± kontrol etme vb.
        pass

    def generate_content(self, system_instruction, prompt_text):
        """AI'dan iÃ§erik Ã¼retme Ã§aÄŸrÄ±sÄ±."""
        raise NotImplementedError("Bu metot alt sÄ±nÄ±flar tarafÄ±ndan uygulanmalÄ±dÄ±r.")
```

#### ğŸ“„ Dosya: `core\deepseek.py`

```py
# core/deepseek.py
import os
import requests
from .base import BaseModel, ModelAPIError
from config import MODEL_CONFIGS

class DeepSeekModel(BaseModel):
    """DeepSeek API - Ãœcretsiz ve gÃ¼Ã§lÃ¼"""
    
    def __init__(self):
        conf = MODEL_CONFIGS["deepseek"]
        self.MODEL_NAME = conf["display_name"]
        
        self.api_key = os.getenv(conf["env_var"])
        if not self.api_key:
            raise ModelAPIError(f"{conf['env_var']} ortam deÄŸiÅŸkeni bulunamadÄ±.")
        
        # DeepSeek OpenAI uyumlu API uÃ§ noktasÄ±
        self.api_url = "https://api.deepseek.com/v1/chat/completions"
        self.model_id = conf["model_id"]
    
    def generate_content(self, system_instruction, prompt_text):
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.model_id,
            "messages": [
                {"role": "system", "content": system_instruction},
                {"role": "user", "content": prompt_text}
            ],
            "temperature": 0.1,
            "max_tokens": 8000,
            "response_format": {"type": "json_object"}  # JSON zorla
        }
        
        try:
            response = requests.post(self.api_url, headers=headers, json=payload, timeout=60)
            response.raise_for_status()
            result = response.json()
            
            # Debug iÃ§in
            if hasattr(self, 'DEBUG') and self.DEBUG:
                print(f"DEBUG DeepSeek Response: {result}")
                
            return result["choices"][0]["message"]["content"].strip()
            
        except requests.exceptions.RequestException as e:
            # Hata mesajÄ±nÄ± daha detaylÄ± gÃ¶rmek iÃ§in
            if hasattr(e, 'response') and e.response is not None:
                error_msg = e.response.text
                print(f"DEBUG DeepSeek Error: {error_msg}")
                try:
                    error_json = json.loads(error_msg)
                    raise ModelAPIError(f"DeepSeek HatasÄ±: {error_json.get('message', str(e))}")
                except:
                    raise ModelAPIError(f"DeepSeek API HatasÄ±: {e}")
            else:
                raise ModelAPIError(f"DeepSeek BaÄŸlantÄ± HatasÄ±: {e}")
        except Exception as e:
            raise ModelAPIError(f"DeepSeek Ä°ÅŸlem HatasÄ±: {e}")
```

#### ğŸ“„ Dosya: `core\gemini.py`

```py
import os
from google import genai
from google.genai import types
from .base import BaseModel, ModelAPIError
from config import MODEL_CONFIGS

class GeminiModel(BaseModel):
    def __init__(self):
        conf = MODEL_CONFIGS["gemini"]
        self.MODEL_NAME = conf["display_name"]
        self.raw_model_name = conf["model_name"] # Fiyat hesaplamasÄ± iÃ§in
        
        api_key = os.getenv(conf["env_var"])
        if not api_key:
            raise ModelAPIError(f"{conf['env_var']} bulunamadÄ±.")

        try:
            self.client = genai.Client(api_key=api_key)
        except Exception as e:
            raise ModelAPIError(f"Gemini Client BaÅŸlatÄ±lamadÄ±: {e}")

    def generate_content(self, system_instruction, prompt_text):
        try:
            response = self.client.models.generate_content(
                model=self.raw_model_name,
                contents=[prompt_text],
                config=types.GenerateContentConfig(
                    system_instruction=system_instruction,
                    temperature=0.1
                )
            )
            
            # Token kullanÄ±mÄ±nÄ± gÃ¼venli ÅŸekilde al
            usage = {
                "input_tokens": 0,
                "output_tokens": 0
            }
            
            if hasattr(response, 'usage_metadata'):
                usage["input_tokens"] = response.usage_metadata.prompt_token_count
                usage["output_tokens"] = response.usage_metadata.candidates_token_count

            return {
                "content": response.text.strip(),
                "usage": usage,
                "model_key": self.raw_model_name
            }

        except Exception as e:
            raise ModelAPIError(f"Gemini HatasÄ±: {e}")
```

#### ğŸ“„ Dosya: `core\groq.py`

```py
# core/groq.py (DOÄRU VERSÄ°YON)
import os
import requests
from .base import BaseModel, ModelAPIError
from config import MODEL_CONFIGS

class GroqModel(BaseModel):
    """Groq LPU - Ultra hÄ±zlÄ± inference"""
    
    def __init__(self):
        conf = MODEL_CONFIGS["groq"]
        self.MODEL_NAME = conf["display_name"]
        
        # âš ï¸ Buradaki atamalarÄ±n doÄŸru yapÄ±ldÄ±ÄŸÄ±ndan emin olun:
        self.api_key = os.getenv(conf["env_var"])
        if not self.api_key:
            raise ModelAPIError(f"{conf['env_var']} ortam deÄŸiÅŸkeni bulunamadÄ±.")
        
        self.api_url = "https://api.groq.com/openai/v1/chat/completions"
        self.model_id = conf["model_id"]
    
    def generate_content(self, system_instruction, prompt_text):
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.model_id,
            "messages": [
                {"role": "system", "content": system_instruction},
                {"role": "user", "content": prompt_text}
            ],
            "temperature": 0.1,
            "max_tokens": 8000,
            "response_format": {"type": "json_object"}  # JSON zorla
        }
        
        try:
            response = requests.post(self.api_url, headers=headers, json=payload, timeout=30)
            response.raise_for_status()
            result = response.json()
            return result["choices"][0]["message"]["content"].strip()
        except Exception as e:
            # Hata mesajÄ±nÄ± daha detaylÄ± gÃ¶rmek iÃ§in
            if hasattr(e, 'response') and e.response is not None:
                 print(f"DEBUG RESPONSE: {e.response.text}")
            raise ModelAPIError(f"Groq API HatasÄ±: {e}")
```

#### ğŸ“„ Dosya: `core\huggingface.py`

```py
# core/huggingface.py
import os
import requests
import json
from .base import BaseModel, ModelAPIError
from config import MODEL_CONFIGS

class HuggingFaceModel(BaseModel):
    def __init__(self):
        conf = MODEL_CONFIGS["huggingface"]
        self.MODEL_NAME = conf["display_name"]
        self.model_id = conf["model_id"]
        
        self.api_key = os.getenv(conf["env_var"])
        if not self.api_key:
            raise ModelAPIError(f"{conf['env_var']} bulunamadÄ±.")
        
        self.headers = {"Authorization": f"Bearer {self.api_key}"}
        self.api_url = f"https://router.huggingface.co/models/{self.model_id}"

    def generate_content(self, system_instruction, prompt_text):
        # --- PROMPT FORMATLAMA ---
        # Qwen ve modern modeller iÃ§in ChatML formatÄ± en iyisidir
        if "qwen" in self.model_id.lower():
            full_prompt = (
                f"<|im_start|>system\n{system_instruction}<|im_end|>\n"
                f"<|im_start|>user\n{prompt_text}<|im_end|>\n"
                f"<|im_start|>assistant\n"
            )
        elif "llama-3" in self.model_id.lower():
            full_prompt = (
                f"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n{system_instruction}<|eot_id|>\n"
                f"<|start_header_id|>user<|end_header_id|>\n{prompt_text}<|eot_id|>\n"
                f"<|start_header_id|>assistant<|end_header_id|>"
            )
        else:
            # VarsayÄ±lan (Mistral/Eski Llama)
            full_prompt = f"[INST] <<SYS>>\n{system_instruction}\n<</SYS>>\n{prompt_text} [/INST]"

        payload = {
            "inputs": full_prompt,
            "parameters": {
                "max_new_tokens": 4096, # Kod Ã¼retimi iÃ§in yÃ¼ksek token
                "temperature": 0.1,     # TutarlÄ±lÄ±k iÃ§in dÃ¼ÅŸÃ¼k sÄ±caklÄ±k
                "return_full_text": False
            }
        }

        try:
            response = requests.post(self.api_url, headers=self.headers, json=payload)
            response.raise_for_status()
            
            result = response.json()
            
            # Hugging Face API bazen liste, bazen dict dÃ¶ner
            if isinstance(result, list) and len(result) > 0:
                return result[0].get('generated_text', '').strip()
            elif isinstance(result, dict):
                return result.get('generated_text', '').strip()
            else:
                raise ModelAPIError(f"Beklenmeyen API yanÄ±t formatÄ±: {type(result)}")

        except Exception as e:
            raise ModelAPIError(f"HF API HatasÄ±: {e}")
```

#### ğŸ“„ Dosya: `core\memory.py`

```py
import os
import shutil
import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
import torch
import config
from config import Colors

class MemoryManager:
    def __init__(self, project_root: str):
        """
        Belirtilen proje dizini iÃ§in izole hafÄ±za yÃ¶neticisi.
        """
        self.project_root = project_root
        self.memory_path = os.path.join(project_root, config.MEMORY_DIR_NAME)
        
        # 1. DonanÄ±m AlgÄ±lama ve Embedding Modelini YÃ¼kleme
        self.device = self._detect_device()
        print(f"{Colors.MAGENTA}ğŸ§  HafÄ±za Motoru BaÅŸlatÄ±lÄ±yor... ({self.device}){Colors.RESET}")
        
        try:
            self.embedder = SentenceTransformer(config.EMBEDDING_MODEL, device=self.device)
        except Exception as e:
            print(f"{Colors.RED}Model yÃ¼kleme hatasÄ±, CPU'ya geÃ§iliyor: {e}{Colors.RESET}")
            self.embedder = SentenceTransformer(config.EMBEDDING_MODEL, device="cpu")

        # 2. ChromaDB Ä°stemcisini BaÅŸlatma (Persistent)
        os.makedirs(self.memory_path, exist_ok=True)
        self.client = chromadb.PersistentClient(path=self.memory_path)
        
        # Koleksiyonu al veya oluÅŸtur
        self.collection = self.client.get_or_create_collection(
            name=config.COLLECTION_NAME,
            metadata={"hnsw:space": "cosine"} # Kod benzerliÄŸi iÃ§in kosinÃ¼s idealdir
        )

    def _detect_device(self) -> str:
        """Sistemi tarar: NVIDIA GPU -> Apple Silicon (MPS) -> CPU"""
        if torch.cuda.is_available():
            return "cuda"
        elif torch.backends.mps.is_available():
            return "mps"
        else:
            return "cpu"

    def index_files(self, file_paths: list):
        """DosyalarÄ± okur, vektÃ¶rleÅŸtirir ve veritabanÄ±na kaydeder."""
        documents = []
        metadatas = []
        ids = []

        print(f"{Colors.CYAN}ğŸ“¥ {len(file_paths)} dosya indeksleniyor...{Colors.RESET}")

        for fpath in file_paths:
            full_path = os.path.join(self.project_root, fpath)
            if not os.path.exists(full_path):
                continue
            
            try:
                with open(full_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # Basit chunking: DosyayÄ± olduÄŸu gibi alÄ±yoruz (kÃ¼Ã§Ã¼k dosyalar iÃ§in)
                # BÃ¼yÃ¼k projelerde buraya "TextSplitter" eklenmeli.
                if len(content.strip()) == 0: continue

                documents.append(content)
                metadatas.append({"source": fpath})
                ids.append(fpath) # ID olarak dosya yolu benzersizdir

            except Exception as e:
                print(f"{Colors.YELLOW}UyarÄ±: {fpath} okunamadÄ± ({e}){Colors.RESET}")

        if documents:
            # Embedding iÅŸlemini manuel yapÄ±p Chroma'ya veriyoruz (Daha fazla kontrol iÃ§in)
            embeddings = self.embedder.encode(documents, normalize_embeddings=True).tolist()
            
            # Upsert: Varsa gÃ¼ncelle, yoksa ekle
            self.collection.upsert(
                documents=documents,
                embeddings=embeddings,
                metadatas=metadatas,
                ids=ids
            )
            print(f"{Colors.GREEN}âœ… HafÄ±za gÃ¼ncellendi.{Colors.RESET}")

    def query(self, prompt: str, n_results=config.MAX_CONTEXT_RESULTS):
        """Prompt ile alakalÄ± kod parÃ§alarÄ±nÄ± getirir."""
        query_embedding = self.embedder.encode([prompt], normalize_embeddings=True).tolist()
        
        results = self.collection.query(
            query_embeddings=query_embedding,
            n_results=n_results
        )
        
        context_parts = []
        if results['documents']:
            for i, doc in enumerate(results['documents'][0]):
                source = results['metadatas'][0][i]['source']
                context_parts.append(f"--- BAÄLAM: {source} ---\n{doc}\n")
        
        return "\n".join(context_parts)

    def clear_memory(self):
        """HafÄ±zayÄ± sÄ±fÄ±rlar."""
        self.client.delete_collection(config.COLLECTION_NAME)
        shutil.rmtree(self.memory_path)
        print(f"{Colors.YELLOW}ğŸ§¹ HafÄ±za temizlendi.{Colors.RESET}")
```
