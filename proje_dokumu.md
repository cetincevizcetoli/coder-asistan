# ğŸ“ Proje DÃ¶kÃ¼mÃ¼: coder-asistan

Bu dÃ¶kÃ¼m, **/home/ahmetc/proje/coder-asistan** dizini iÃ§in oluÅŸturulmuÅŸtur.
Not: `my_projects` klasÃ¶rÃ¼nÃ¼n iÃ§eriÄŸi gizlilik gereÄŸi hariÃ§ tutulmuÅŸtur.

### ğŸ“‚ Proje Dizin YapÄ±sÄ± ve Dosyalar

- **coder-asistan/** (Proje KÃ¶kÃ¼)
  - .gitignore
  - ARCHITECTURE.md
  - assistant.py
  - check_models.py
  - config.py
  - debug.py
  - generate_docs.py
  - launcher.py
  - migrate_projects.py
  - model_selector.py
  - proje_dokumu.md
  - readme.md
  - requirements.txt
  - settings_menu.py
  - system_audit.py
  - user_settings.json
  - **temp_install_dir/**
  - **core/**
    - base.py
    - deepseek.py
    - gemini.py
    - groq.py
    - huggingface.py
    - memory.py
  - **my_projects/** (KullanÄ±cÄ± Projeleri - Ä°Ã§erik Gizli)

---
### ğŸ’» Kod Ä°Ã§eriÄŸi DÃ¶kÃ¼mÃ¼


#### ğŸ“„ Dosya: `ARCHITECTURE.md`

```md
# ğŸ—ï¸ Coder-Asistan: Teknik Mimari ve GeliÅŸtirici KÄ±lavuzu

Bu belge, **Coder-Asistan** projesinin iÃ§ yapÄ±sÄ±nÄ±, veri akÄ±ÅŸÄ±nÄ±, tasarÄ±m kararlarÄ±nÄ± ve sistemin "neden" bÃ¶yle Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± anlatan teknik referanstÄ±r.

Proje, basit bir script deÄŸil; modÃ¼ler, RAG (Retrieval-Augmented Generation) tabanlÄ± ve durum (state) korumalÄ± bir **CLI Kodlama StÃ¼dyosu**dur.

---

## 1. ğŸ—ºï¸ KuÅŸ BakÄ±ÅŸÄ± Sistem Mimarisi

Sistem 4 ana katmandan oluÅŸur:

1.  **YÃ¶netim KatmanÄ± (Launcher):** KullanÄ±cÄ±yÄ± karÅŸÄ±lar, proje izolasyonunu saÄŸlar ve Ã§alÄ±ÅŸma dizinini ayarlar.
2.  **Beyin KatmanÄ± (Assistant & Config):** KullanÄ±cÄ± isteÄŸini iÅŸler, maliyeti hesaplar ve AI'ya "JSON formatÄ±nda" emir verir.
3.  **HafÄ±za KatmanÄ± (RAG Core):** Projedeki kodlarÄ± vektÃ¶rleÅŸtirir (Embedding) ve anlamsal arama yapar.
4.  **AdaptÃ¶r KatmanÄ± (Model Core):** FarklÄ± AI saÄŸlayÄ±cÄ±larÄ±nÄ± (Gemini, Groq, HF) tek bir standart arayÃ¼ze dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.


```text
      [ KULLANICI ]
           â”‚
           â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   LAUNCHER.PY   â”‚  (1. GiriÅŸ KapÄ±sÄ± & Proje SeÃ§imi)
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  ASSISTANT.PY   â”‚ â—„â”€â”€â”€â–º â”‚  CONFIG (Kurallar)â”‚
  â”‚ (Karar Motoru)  â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ”€â”€â”€â–º [ ğŸ§  HAFIZA (RAG) ] â—„â”€â”€â”€ (.coder_memory)
           â”‚      (KodlarÄ± HatÄ±rlar)
           â”‚
           â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   MODEL CORE    â”‚  (AdaptÃ¶r KatmanÄ±)
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ”€â”€â”€â–º Google Gemini
           â”œâ”€â”€â”€â–º Groq Llama 3
           â””â”€â”€â”€â–º DeepSeek / HF

---

## 2. ğŸ“‚ Dizin YapÄ±sÄ± ve Sorumluluklar

```text
coder-asistan/
â”œâ”€â”€ launcher.py           # [ENTRY POINT] Proje seÃ§imi ve ortam hazÄ±rlÄ±ÄŸÄ±
â”œâ”€â”€ assistant.py          # [MAIN LOOP] Ä°stek-Cevap dÃ¶ngÃ¼sÃ¼ ve dosya iÅŸlemleri
â”œâ”€â”€ config.py             # [SETTINGS] Sabitler, Promptlar ve FiyatlandÄ±rma
â”œâ”€â”€ requirements.txt      # BaÄŸÄ±mlÄ±lÄ±klar
â”‚
â”œâ”€â”€ my_projects/          # [USER DATA] KullanÄ±cÄ± projelerinin fiziksel konumu
â”‚   â””â”€â”€ proje_x/          # -> Ä°zole Ã‡alÄ±ÅŸma AlanÄ±
â”‚       â”œâ”€â”€ .coder_memory/ # -> ChromaDB (VektÃ¶r VeritabanÄ±)
â”‚       â”œâ”€â”€ .chat_history/ # -> Loglar
â”‚       â””â”€â”€ src/           # -> KullanÄ±cÄ± KodlarÄ±
â”‚
â”œâ”€â”€ core/                 # [BACKEND] Sistem Ã§ekirdeÄŸi
â”‚   â”œâ”€â”€ base.py           # -> Soyut Model SÄ±nÄ±fÄ± (Interface)
â”‚   â”œâ”€â”€ memory.py         # -> RAG Motoru (SentenceTransformers + ChromaDB)
â”‚   â”œâ”€â”€ gemini.py         # -> Google Adapter
â”‚   â””â”€â”€ groq.py           # -> Groq Adapter
â”‚
â””â”€â”€ utils/ (Opsiyonel)    # YardÄ±mcÄ± araÃ§lar (debug.py, system_audit.py vb.)
```

---

## 3. âš™ï¸ Veri AkÄ±ÅŸÄ± (Bir Komutun YolculuÄŸu)

KullanÄ±cÄ± `python launcher.py` Ã§alÄ±ÅŸtÄ±rÄ±p bir projeye girdiÄŸinde ve "HatayÄ± dÃ¼zelt" dediÄŸinde arka planda ÅŸu olaylar zinciri gerÃ§ekleÅŸir:

### AdÄ±m 1: BaÄŸlamÄ±n YÃ¼klenmesi (Context Loading)
* `assistant.py`, `core.memory.MemoryManager`'Ä± baÅŸlatÄ±r.
* KullanÄ±cÄ±nÄ±n sorusu ("HatayÄ± dÃ¼zelt"), `SentenceTransformer` modeli ile **vektÃ¶re** (sayÄ±sal diziye) Ã§evrilir.
* ChromaDB iÃ§inde bu vektÃ¶re matematiksel olarak en yakÄ±n olan kod parÃ§alarÄ± (Chunks) bulunur.

### AdÄ±m 2: Prompt MÃ¼hendisliÄŸi (Prompt Engineering)
AI'ya giden metin ÅŸu ÅŸablonda birleÅŸtirilir:
1.  **Sistem Emri (`config.SYSTEM_INSTRUCTION`):** "Sen bir JSON makinesisin. Asla sohbet etme."
2.  **RAG BaÄŸlamÄ±:** "VeritabanÄ±ndan bulduÄŸum ilgili kodlar ÅŸunlar: ..."
3.  **KullanÄ±cÄ± Ä°steÄŸi:** "HatayÄ± dÃ¼zelt."

### AdÄ±m 3: Model Ã‡aÄŸrÄ±sÄ± ve Adaptasyon
* SeÃ§ili model (Ã–rn: Gemini), `core/gemini.py` Ã¼zerinden Ã§aÄŸrÄ±lÄ±r.
* Her model farklÄ± yanÄ±t verse de (Object, Dict, Text), adaptÃ¶rler bunu standart bir formata Ã§evirir.

### AdÄ±m 4: JSON TemizliÄŸi ve GÃ¼venlik
* AI'dan gelen yanÄ±t `clean_json_string()` fonksiyonuna girer. Markdown etiketleri (` ```json `) temizlenir.
* Saf JSON parse edilir.
* **GÃ¼venlik:** AI "BilgisayarÄ± kapat" diyemez. Sadece `dosya_olustur` veya `dosya_sil` komutlarÄ± iÅŸlenir.

### AdÄ±m 5: Ä°ÅŸlem ve Yedekleme
* Dosya yazÄ±lmadan Ã¶nce `backup_file()` fonksiyonu devreye girer.
* Hedef dosyanÄ±n bir kopyasÄ± `.gassist_backups` klasÃ¶rÃ¼ne zaman damgasÄ±yla (timestamp) kaydedilir.
* Yeni iÃ§erik yazÄ±lÄ±r.

---

## 4. ğŸ”§ Kritik KonfigÃ¼rasyonlar (`config.py`)

GeliÅŸtiricilerin bilmesi gereken hassas ayarlar:

* **`SYSTEM_INSTRUCTION`:** Sistemsel prompt. AI'nÄ±n "Suskun" olmasÄ±nÄ± saÄŸlayan yer burasÄ±dÄ±r. Buradaki kurallar gevÅŸetilirse sistemin JSON parse yeteneÄŸi bozulabilir.
* **`MAX_FILE_SIZE`:** VarsayÄ±lan 5MB. AI'nÄ±n token limitini patlatmamasÄ± iÃ§in bÃ¼yÃ¼k dosyalar (loglar, binaryler) okunmaz.
* **`PRICING_RATES`:** Maliyet hesaplama tablosu. Statiktir, API fiyatlarÄ± deÄŸiÅŸirse manuel gÃ¼ncellenmelidir.

---

## 5. ğŸ› ï¸ GeliÅŸtirici AraÃ§ Seti (DevTools)

Projeyi debug etmek veya yÃ¶netmek iÃ§in kullanÄ±lan "Ä°sviÃ§re Ã‡akÄ±sÄ±" araÃ§larÄ±:

| AraÃ§ | Dosya | GÃ¶revi |
| :--- | :--- | :--- |
| **HafÄ±za MÃ¼fettiÅŸi** | `debug.py` | ChromaDB veritabanÄ±na baÄŸlanÄ±r, vektÃ¶rleri ve kayÄ±tlÄ± kod parÃ§alarÄ±nÄ± ham haliyle gÃ¶sterir. |
| **Sistem Doktoru** | `system_audit.py` | Dosya izinlerini, log boyutlarÄ±nÄ± ve veritabanÄ± bÃ¼tÃ¼nlÃ¼ÄŸÃ¼nÃ¼ (integrity) kontrol eder. |
| **Proje TaÅŸÄ±yÄ±cÄ±** | `migrate_projects.py` | `my_projects` dÄ±ÅŸÄ±ndaki "sahipsiz" projeleri bulup iÃ§eriye taÅŸÄ±r. |
| **Belgeleyici** | `generate_docs.py` | TÃ¼m kod yapÄ±sÄ±nÄ± tek bir Markdown dosyasÄ±na dÃ¶ker (LLM analizi iÃ§in). |

---

## 6. ğŸš€ Gelecek PlanlarÄ± ve GeniÅŸletilebilirlik

Bu mimari ÅŸunlara izin verecek ÅŸekilde tasarlanmÄ±ÅŸtÄ±r:
* **Yeni Model Ekleme:** Sadece `core/` altÄ±na yeni bir `.py` dosyasÄ± ekleyerek.
* **Resim DesteÄŸi:** `assistant.py` gÃ¼ncellenerek Gemini 1.5 Pro'nun Vision Ã¶zellikleri aÃ§Ä±labilir.
* **Web ArayÃ¼zÃ¼:** Logic (MantÄ±k) ve UI (ArayÃ¼z) ayrÄ±ldÄ±ÄŸÄ± iÃ§in, `launcher.py` yerine bir `app.py` (Flask/Streamlit) yazÄ±larak kolayca web'e taÅŸÄ±nabilir.

---
**GeliÅŸtirici:** Ahmet Ã‡etin
*Bu dokÃ¼man Coder-Asistan v2.0 mimarisini yansÄ±tÄ±r.*
```

#### ğŸ“„ Dosya: `assistant.py`

```py
import sys
import os
import re
import json
import shutil
import time
import requests
from datetime import datetime
from typing import List, Optional, Any, Tuple, Dict

# --- PROJE MODÃœLLERÄ° ---
try:
    import config
    from config import Colors, PRICING_RATES
    from core.memory import MemoryManager
    from core.gemini import GeminiModel 
except ImportError:
    import config

# --- SABÄ°TLER ---
FILE_PATTERN = re.compile(r"[\w-]+\.(py|js|html|css|md|json|txt|java|cpp|h|ts|jsx|tsx|sh|env|sql|xml|yaml)", re.IGNORECASE)

# ==========================================
# ğŸ› ï¸ YARDIMCI FONKSÄ°YONLAR
# ==========================================

def is_safe_path(file_path: str, current_directory: str) -> bool:
    """Dosya yolunun proje klasÃ¶rÃ¼ dÄ±ÅŸÄ±na Ã§Ä±kÄ±p Ã§Ä±kmadÄ±ÄŸÄ±nÄ± kontrol eder."""
    try:
        # 1. Mutlak yollarÄ± engelle (Ã¶rn: /etc/passwd)
        if os.path.isabs(file_path): 
            return False
        
        # 2. '..' iÃ§eren yollarÄ± engelle
        if '..' in file_path:
            return False
            
        # 3. YollarÄ± tam yola (absolute path) Ã§evirip kÄ±yasla
        target_path = os.path.abspath(os.path.join(current_directory, file_path))
        safe_root = os.path.abspath(current_directory)
        
        return target_path.startswith(safe_root)
    except:
        return False

def clean_json_string(json_string: str) -> Optional[Dict]:
    try:
        if "```" in json_string:
            lines = json_string.split('\n')
            clean_lines = []
            capture = False
            for line in lines:
                if "```" in line:
                    capture = not capture
                    continue
                if capture:
                    clean_lines.append(line)
            if clean_lines:
                json_string = "\n".join(clean_lines)
            else:
                json_string = json_string.replace("```json", "").replace("```", "")

        json_string = json_string.strip()
        if json_string.rfind('}') != -1:
            json_string = json_string[:json_string.rfind('}')+1]
        
        return json.loads(json_string)
    except Exception:
        return None

def backup_file(full_path: str) -> Optional[str]:
    if not os.path.exists(full_path): return None
    os.makedirs(config.BACKUP_DIR, exist_ok=True)
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    backup_name = f"{os.path.basename(full_path)}.{timestamp}.backup"
    shutil.copy(full_path, os.path.join(config.BACKUP_DIR, backup_name))
    return backup_name

def log_conversation(working_dir: str, user_prompt: str, ai_explanation: str, model_name: str, cost: float = 0.0):
    log_file = os.path.join(working_dir, ".chat_history.log")
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M')
    
    log_entry = (
        f"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
        f"ğŸ“… ZAMAN: {timestamp} | ğŸ¤– MODEL: {model_name}\n"
        f"ğŸ’° MALÄ°YET: ${cost:.5f}\n"
        f"ğŸ‘¤ USER: {user_prompt}\n"
        f"ğŸ¤– AI:   {ai_explanation}\n"
    )
    try:
        with open(log_file, "a", encoding="utf-8") as f:
            f.write(log_entry)
    except: pass

def update_project_stats(working_dir: str, usage_data: dict, model_key: str) -> Tuple[float, float]:
    stats_file = os.path.join(working_dir, ".project_stats.json")
    stats = {"total_cost": 0.0, "total_input_tokens": 0, "total_output_tokens": 0, "last_updated": ""}

    if os.path.exists(stats_file):
        try:
            with open(stats_file, 'r', encoding='utf-8') as f:
                stats = json.load(f)
        except: pass

    in_tokens = usage_data.get("input_tokens", 0)
    out_tokens = usage_data.get("output_tokens", 0)
    rates = PRICING_RATES.get(model_key, {"input": 0, "output": 0})
    
    current_cost = ((in_tokens / 1_000_000) * rates["input"]) + ((out_tokens / 1_000_000) * rates["output"])

    stats["total_cost"] += current_cost
    stats["total_input_tokens"] += in_tokens
    stats["total_output_tokens"] += out_tokens
    stats["last_updated"] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

    try:
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=4)
    except: pass

    return current_cost, stats["total_cost"]

def print_cost_report(current_cost: float, total_cost: float, usage_data: dict):
    in_tokens = usage_data.get("input_tokens", 0)
    out_tokens = usage_data.get("output_tokens", 0)
    
    if config.USER_TIER == 'free':
        c_str, t_str = "$0.00000", "$0.00000"
    else:
        c_str, t_str = f"${current_cost:.5f}", f"${total_cost:.5f}"

    print(f"\n{Colors.GREY}ğŸ“Š RAPOR: Girdi: {in_tokens} | Ã‡Ä±ktÄ±: {out_tokens} | Maliyet: {Colors.GREEN}{c_str}{Colors.RESET}")
    print(f"{Colors.GREY}   ğŸ’° PROJE TOPLAMI: {t_str}{Colors.RESET}")

# ==========================================
# ğŸš€ TEKÄ°L Ä°ÅLEM
# ==========================================

def process_single_turn(prompt_text: str, model_instance: Any, working_dir: str, memory: Any, is_dry_run: bool = False):
    
    # 1. HafÄ±za
    rag_context = ""
    if memory:
        print(f"{Colors.CYAN}ğŸ” HafÄ±za taranÄ±yor...{Colors.RESET}")
        rag_context = memory.query(prompt_text, n_results=config.MAX_CONTEXT_RESULTS)
        if len(rag_context) > config.MAX_CONTEXT_CHARS:
            rag_context = rag_context[:config.MAX_CONTEXT_CHARS] + "\n...(KÄ±rpÄ±ldÄ±)..."

    full_prompt = (
        f"--- PROJE BAÄLAMI ---\n{rag_context}\n\n"
        f"--- KULLANICI Ä°STEÄÄ° ---\n{prompt_text}\n"
    )
        
    print(f"{Colors.BLUE}âœ… Ä°ÅLENÄ°YOR:{Colors.RESET} {prompt_text}")
    
    ai_response_plan = {}
    current_cost = 0.0
    
    # 2. Model
    while True:
        try:
            print(f"{Colors.CYAN}â³ {model_instance.MODEL_NAME} yanÄ±t Ã¼retiyor...{Colors.RESET}")
            response_data = model_instance.generate_content(config.SYSTEM_INSTRUCTION, full_prompt)
            
            if isinstance(response_data, str):
                raw_text = response_data; usage = {}; key = "unknown"
            else:
                raw_text = response_data["content"]; usage = response_data["usage"]; key = response_data["model_key"]

            ai_response_plan = clean_json_string(raw_text)
            
            if ai_response_plan is None:
                print(f"{Colors.RED}âš ï¸ Format hatasÄ±. Tekrar deneniyor...{Colors.RESET}")
                continue

            current_cost, total_cost = update_project_stats(working_dir, usage, key)
            print_cost_report(current_cost, total_cost, usage)
            break 

        except Exception as e:
            print(f"\n{Colors.RED}Hata: {e}{Colors.RESET}")
            return

    # 3. Onay ve Uygulama
    explanation = ai_response_plan.get("aciklama", "AÃ§Ä±klama yok.")
    files_create = ai_response_plan.get("dosya_olustur", {})
    files_delete = ai_response_plan.get("dosya_sil", [])

    print(f"\n{Colors.MAGENTA}ğŸ¤– AI:{Colors.RESET} {Colors.CYAN}{explanation}{Colors.RESET}")
    
    if not files_create and not files_delete:
        print(f"{Colors.YELLOW}(DeÄŸiÅŸiklik Ã¶nerilmedi){Colors.RESET}")
        log_conversation(working_dir, prompt_text, explanation, model_instance.MODEL_NAME, current_cost)
        return

    print("\nğŸ“‹ PLANLANAN DEÄÄ°ÅÄ°KLÄ°KLER:")
    for p in files_create: print(f"   ğŸ“‚ + {p}")
    for p in files_delete: print(f"   ğŸ—‘ï¸  - {p}")

    if is_dry_run: return

    # .strip() ekledik ki boÅŸluklu 'e ' yazÄ±larÄ±nÄ± da kabul etsin.
    confirm = input(f"\n{Colors.GREEN}OnaylÄ±yor musunuz? (e/h): {Colors.RESET}").strip().lower()
    
    if confirm == 'e':
        # SÄ°LME Ä°ÅLEMÄ°
        for p in files_delete:
            if is_safe_path(p, working_dir):
                full = os.path.join(working_dir, p)
                if os.path.exists(full):
                    backup_file(full); os.remove(full)
                    print(f"{Colors.RED}Silindi: {p}{Colors.RESET}")
            else:
                print(f"{Colors.RED}ğŸš¨ GÃœVENLÄ°K ENGELÄ° (Silinemedi): {p}{Colors.RESET}")

        # OLUÅTURMA Ä°ÅLEMÄ°
        for p, content in files_create.items():
            if is_safe_path(p, working_dir):
                full = os.path.join(working_dir, p)
                try:
                    os.makedirs(os.path.dirname(full), exist_ok=True)
                    if os.path.exists(full): backup_file(full)
                    with open(full, 'w', encoding='utf-8') as f: f.write(content)
                    print(f"{Colors.GREEN}YazÄ±ldÄ±: {p}{Colors.RESET}")
                    if memory: memory.index_files([p])
                except Exception as e:
                     print(f"{Colors.RED}Hata (Yazma): {e}{Colors.RESET}")
            else:
                # Sessiz kalmak yerine hatayÄ± gÃ¶steriyoruz
                print(f"{Colors.RED}ğŸš¨ GÃœVENLÄ°K ENGELÄ° (YazÄ±lamadÄ±): {p}{Colors.RESET}")
                print(f"   (Sebep: Dosya yolu proje dizininin dÄ±ÅŸÄ±na Ã§Ä±kmaya Ã§alÄ±ÅŸÄ±yor veya yol uyuÅŸmazlÄ±ÄŸÄ± var.)")

        log_conversation(working_dir, prompt_text, explanation, model_instance.MODEL_NAME, current_cost)
    else:
        print("âŒ Ä°ptal edildi.")

# ==========================================
# ğŸŒŸ MAIN FONKSÄ°YONU
# ==========================================

def main(project_name):
    # DÃœZELTME: os.path.abspath kullanarak yolu kesinleÅŸtiriyoruz.
    # BÃ¶ylece is_safe_path ÅŸaÅŸÄ±rmayacak.
    project_path = os.path.abspath(os.path.join(config.PROJECTS_DIR, project_name))
    
    if not os.path.exists(project_path):
        print(f"Hata: {project_path} bulunamadÄ±.")
        return

    print(f"\n{Colors.GREEN}ğŸš€ PROJE BAÅLATILIYOR: {project_name.upper()}{Colors.RESET}")

    # VarsayÄ±lan Model: Gemini
    model_instance = None
    try:
        model_instance = GeminiModel()
    except Exception as e:
        print(f"{Colors.RED}Gemini baÅŸlatÄ±lamadÄ±: {e}{Colors.RESET}")
        return

    # HafÄ±za
    memory = None
    try:
        memory = MemoryManager(project_root=project_path)
    except: pass

    print(f"{Colors.CYAN}--------------------------------------------------{Colors.RESET}")
    print(f"Sohbet baÅŸladÄ±. Ã‡Ä±kmak iÃ§in 'exit' veya 'q' yazÄ±n.")
    
    while True:
        try:
            user_input = input(f"\n{Colors.BOLD}{Colors.YELLOW}({project_name}) Siz > {Colors.RESET}").strip()
            
            if user_input.lower() in ['exit', 'q', 'quit', 'b']:
                print("ğŸ‘‹ Ã‡Ä±kÄ±lÄ±yor...")
                break
            
            if not user_input: continue
            
            process_single_turn(user_input, model_instance, project_path, memory)
            
        except KeyboardInterrupt:
            break
        except Exception as e:
            print(f"Hata: {e}")

if __name__ == "__main__":
    if len(sys.argv) > 1:
        # Tekil test iÃ§in de mutlak yol kullanalÄ±m
        cwd = os.path.abspath(os.getcwd())
        try:
            model = GeminiModel()
            process_single_turn(" ".join(sys.argv[1:]), model, cwd, None)
        except: pass
    else:
        print("Launcher kullanÄ±n.")
```

#### ğŸ“„ Dosya: `check_models.py`

```py
import os
import sys

# google-genai yÃ¼klÃ¼ mÃ¼ kontrol et
try:
    from google import genai
except ImportError:
    print("âŒ HATA: 'google-genai' kÃ¼tÃ¼phanesi bulunamadÄ±.")
    sys.exit(1)

api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    print("âŒ HATA: GOOGLE_API_KEY tanÄ±mlÄ± deÄŸil!")
    sys.exit(1)

print(f"ğŸ”‘ Anahtar ile baÄŸlanÄ±lÄ±yor... (Son 4 hane: {api_key[-4:]})")

try:
    client = genai.Client(api_key=api_key)
    print("\nğŸ“¡ --- HESABINIZDA AKTÄ°F OLAN MODELLER ---")
    
    count = 0
    # Modelleri Ã§ek ve listele
    # Pager Ã¼zerinden dÃ¶ner, listeye Ã§evirelim
    for m in client.models.list():
        # Sadece iÃ§erik Ã¼retebilen modelleri al
        if "generateContent" in m.supported_actions:
            # Ä°smi temizle (models/ Ã¶nekini at)
            clean_name = m.name.replace('models/', '')
            print(f"âœ… {clean_name}")
            count += 1
            
    if count == 0:
        print("\nâš ï¸ HATA: HiÃ§bir model bulunamadÄ±. API Key'inizin yetkilerini kontrol edin.")
    else:
        print("\nğŸ‘‰ Ä°PUCU: YukarÄ±daki âœ… ile baÅŸlayan isimlerden birini config.py dosyasÄ±na kopyalayÄ±n.")

except Exception as e:
    print(f"\nâŒ BAÄLANTI HATASI: {e}")
```

#### ğŸ“„ Dosya: `config.py`

```py
import os

# ==========================================
# ğŸ¨ RENK AYARLARI
# ==========================================
class Colors:
    GREEN = '\033[92m'
    RED = '\033[91m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    CYAN = '\033[96m'
    MAGENTA = '\033[95m'
    GREY = '\033[90m'
    BOLD = '\033[1m'
    RESET = '\033[0m'

# ==========================================
# âš™ï¸ SÄ°STEM VE DOSYA AYARLARI
# ==========================================
MAX_FILE_SIZE = 5 * 1024 * 1024
MAX_TOTAL_SIZE = 20 * 1024 * 1024
BACKUP_DIR = ".gassist_backups"
MAX_BACKUPS_PER_FILE = 5
MEMORY_DIR_NAME = ".coder_memory"
COLLECTION_NAME = "project_codebase"
EMBEDDING_MODEL = "paraphrase-multilingual-MiniLM-L12-v2"
MAX_CONTEXT_RESULTS = 3
MAX_CONTEXT_CHARS = 12000
MAX_BACKUPS_PER_FILE = 10


# YENÄ°: Projelerin toplanacaÄŸÄ± ana klasÃ¶r
PROJECTS_DIR = "my_projects"

# ==========================================
# ğŸ’° MALÄ°YET VE KATMAN
# ==========================================
USER_TIER = 'free' 
PRICING_RATES = {
    "gemini-2.5-flash-lite": { "input": 0.075, "output": 0.30 },
    "gemini-2.5-flash": { "input": 0.10, "output": 0.40 },
    "llama-3.3-70b-versatile": { "input": 0.59, "output": 0.79 },
    "deepseek-chat": { "input": 0.14, "output": 0.28 },
    "Qwen/Qwen2.5-Coder-7B-Instruct": { "input": 0.0, "output": 0.0 }
}

# ==========================================
# ğŸ¤– MODEL AYARLARI
# ==========================================

MODEL_CONFIGS = {
    "gemini": {
        "env_var": "GOOGLE_API_KEY",
        "model_name": "gemini-2.5-flash-lite", 
        "display_name": "Google Gemini 2.5 Flash Lite",
    },
    "groq": {
        "env_var": "GROQ_API_KEY",
        "model_id": "llama-3.3-70b-versatile",
        "display_name": "Groq Llama 3.3 70B",
    },
    "deepseek": {
        "env_var": "DEEPSEEK_API_KEY",
        "model_id": "deepseek-chat",
        "display_name": "DeepSeek Chat",
    },
    "huggingface": {
        "env_var": "HUGGINGFACE_API_KEY",
        "model_id": "Qwen/Qwen2.5-Coder-7B-Instruct",
        "display_name": "Hugging Face Qwen",
    }
}
ACTIVE_PROFILE = 'gemini'
# ==========================================
# ğŸš€ AKTÄ°F PROFÄ°L SEÃ‡Ä°MÄ° (Eksik Olan KÄ±sÄ±m)
# ==========================================
# Buraya MODEL_CONFIGS iÃ§indeki anahtarlardan birini yazmalÄ±sÄ±n:
# SeÃ§enekler: 'gemini', 'groq', 'deepseek', 'huggingface'


# ==========================================
# ğŸ§  YENÄ° AI SÄ°STEM TALÄ°MATI (AkÄ±llÄ± JSON Modu)
# ==========================================
SYSTEM_INSTRUCTION = (
    "Sen uzman bir yazÄ±lÄ±m mimarÄ± ve kodlama asistanÄ±sÄ±n. "
    "GÃ¶revin: Verilen talimatlara ve RAG hafÄ±zasÄ±ndan gelen baÄŸlama gÃ¶re projeyi yÃ¶netmektir.\n"
    "KURALLAR:\n"
    "1. YanÄ±tÄ±n SADECE ve SADECE geÃ§erli bir JSON objesi olmalÄ±dÄ±r.\n"
    "2. JSON formatÄ± ÅU ÅEKÄ°LDE OLMALIDIR:\n"
    "{\n"
    "  'aciklama': 'YaptÄ±ÄŸÄ±nÄ±z iÅŸlemin kÄ±sa bir Ã¶zeti ve nedeni (Ã–rn: HatalÄ± yolu dÃ¼zelttim)',\n"
    "  'dosya_olustur': {'dosya_yolu': 'icerik', 'dosya_yolu2': 'icerik'},\n"
    "  'dosya_sil': ['silinecek_dosya_yolu_1', 'silinecek_dosya_yolu_2']\n"
    "}\n"
    "3. EÄŸer silinecek dosya yoksa 'dosya_sil': [] gÃ¶nder.\n"
    "4. Asla Markdown (```json ... ```) kullanma, sadece saf JSON dÃ¶ndÃ¼r.\n"
    "5. TÃ¼rkÃ§e karakterleri UTF-8 olarak koru."
)


# ==========================================
# ğŸ§  HAFIZA PROFÄ°LLERÄ° (MenÃ¼de GÃ¶rÃ¼necekler)
# ==========================================
MEMORY_PROFILES = {
    "1": {
        "model_name": "all-MiniLM-L6-v2",
        "display": "Hafif (Light)",
        "desc": "ğŸš€ En HÄ±zlÄ±sÄ± | DÃ¼ÅŸÃ¼k RAM | 384 Boyut | Genel projeler iÃ§in ideal.",
        "dim": 384
    },
    "2": {
        "model_name": "paraphrase-multilingual-MiniLM-L12-v2",
        "display": "Dengeli (Medium)",
        "desc": "âš–ï¸  Daha Ä°yi TÃ¼rkÃ§e | Orta HÄ±z | 384 Boyut | KarmaÅŸÄ±k metinler iÃ§in.",
        "dim": 384
    },
    "3": {
        "model_name": "all-mpnet-base-v2",
        "display": "GÃ¼Ã§lÃ¼ (Heavy)",
        "desc": "ğŸ§  En YÃ¼ksek DoÄŸruluk | YavaÅŸ | 768 Boyut | Akademik/Derin analiz iÃ§in.",
        "dim": 768
    }
}

```

#### ğŸ“„ Dosya: `debug.py`

```py
import os
import sys
import chromadb
from pathlib import Path

# Config'den proje klasÃ¶r ismini Ã§ekelim
try:
    import config
    PROJECTS_DIR_NAME = config.PROJECTS_DIR
except ImportError:
    PROJECTS_DIR_NAME = "my_projects"

# Renkler
CYAN = '\033[96m'
GREEN = '\033[92m'
YELLOW = '\033[93m'
RED = '\033[91m'
RESET = '\033[0m'

def list_projects():
    # DÃœZELTME: ArtÄ±k ana dizine deÄŸil, my_projects klasÃ¶rÃ¼ne bakÄ±yoruz
    workspace = Path.cwd() / PROJECTS_DIR_NAME
    
    if not workspace.exists():
        print(f"{RED}Hata: {PROJECTS_DIR_NAME} klasÃ¶rÃ¼ bulunamadÄ±.{RESET}")
        return []

    projects = []
    for entry in workspace.iterdir():
        # .coder_memory klasÃ¶rÃ¼ olanlarÄ± proje say
        if entry.is_dir() and (entry / ".coder_memory").exists():
            projects.append(entry)
    return projects

def inspect_memory(project_path):
    memory_path = project_path / ".coder_memory"
    
    print(f"\n{CYAN}ğŸ§  VeritabanÄ± BaÄŸlanÄ±yor: {memory_path}{RESET}")
    
    try:
        # ChromaDB istemcisi
        client = chromadb.PersistentClient(path=str(memory_path))
        
        # Koleksiyonu bulmaya Ã§alÄ±ÅŸ
        try:
            # Config'deki ismi kullanÄ±yoruz
            collection = client.get_collection("project_codebase")
        except:
            print(f"{RED}âš ï¸ Koleksiyon bulunamadÄ±. VeritabanÄ± bozuk olabilir.{RESET}")
            return
        
        count = collection.count()
        print(f"{GREEN}ğŸ“Š Toplam KayÄ±tlÄ± ParÃ§a (Chunk): {count}{RESET}")
        
        if count == 0:
            print(f"{RED}âš ï¸ HafÄ±za boÅŸ! HenÃ¼z hiÃ§bir dosya indekslenmemiÅŸ.{RESET}")
            return

        print(f"\n{YELLOW}--- SON KAYDEDÄ°LEN 5 VERÄ° (Ã–rnek) ---{RESET}")
        
        # Ä°lk 5 veriyi Ã§ek
        data = collection.peek(limit=5)
        
        if not data['ids']:
            print("Veri Ã§ekilemedi.")
            return

        ids = data['ids']
        metadatas = data['metadatas']
        documents = data['documents']
        
        for i in range(len(ids)):
            doc_id = ids[i]
            meta = metadatas[i] if metadatas else "{}"
            content = documents[i] if documents else ""
            
            # Ä°Ã§erik Ã§ok uzunsa kÄ±saltarak gÃ¶ster
            preview = content[:150].replace('\n', ' ') + "..."
            
            print(f"[{i+1}] ID: {doc_id}")
            print(f"    Kaynak: {meta}")
            print(f"    Ä°Ã§erik: {preview}\n")
            
    except Exception as e:
        print(f"{RED}Hata: {e}{RESET}")
        print("VeritabanÄ± okunamadÄ±. C++ Build Tools eksik olabilir veya DB kilitli.")

if __name__ == "__main__":
    os.system('cls' if os.name == 'nt' else 'clear')
    print(f"ğŸ•µï¸  RAG HAFIZA MÃœFETTÄ°ÅÄ° (Hedef: {PROJECTS_DIR_NAME}/)")
    print("------------------------------------------------")
    
    projects = list_projects()
    
    if not projects:
        print(f"{YELLOW}HiÃ§ proje bulunamadÄ±.{RESET}")
        print(f"Not: Projelerinizin '{PROJECTS_DIR_NAME}' klasÃ¶rÃ¼nde olduÄŸundan emin olun.")
        sys.exit()
        
    for idx, p in enumerate(projects, 1):
        print(f"[{idx}] {p.name}")
        
    print("\n[Q] Ã‡Ä±kÄ±ÅŸ")
    choice = input("\nHangi projeyi inceleyelim? (No): ").strip()
    
    if choice.lower() == 'q':
        sys.exit()
        
    if choice.isdigit() and 1 <= int(choice) <= len(projects):
        inspect_memory(projects[int(choice)-1])
    else:
        print("GeÃ§ersiz seÃ§im.")
```

#### ğŸ“„ Dosya: `generate_docs.py`

```py
import os
import sys

# ==========================================
# âš™ï¸ AYARLAR VE FÄ°LTRELER
# ==========================================

# Sadece iÃ§eriÄŸi taranmayacak sistem klasÃ¶rleri
DIKKATE_ALINMAYACAK_DIZINLER = [
    '.git', '__pycache__', 'venv', '.venv', 'env', '.env', 'node_modules', 
    '.vscode', '.idea', 'dist', 'build', 'target', 'bin',
    '__macosx', '.ds_store', 'logs', 'site-packages', 'lib', 'include',
    '.gassist_backups', '.coder_memory'
]

# Ä°Ã§eriÄŸi dÃ¶kÃ¼lmeyecek ama varlÄ±ÄŸÄ± gÃ¶sterilecek "Ã–zel" klasÃ¶rler
OZEL_USER_KLASORLERI = ['my_projects']

# Ä°Ã§eriÄŸi dÃ¶kÃ¼me eklenecek kod uzantÄ±larÄ±
BELGELENECEK_KOD_UZANTILARI = [
    '.py', '.php', '.js', '.html', '.css', '.json', '.xml', '.yaml', '.yml', 
    '.sh', '.bash', '.c', '.cpp', '.h', '.hpp', '.java', '.go', '.rb', '.swift', 
    '.kt', '.ts', '.jsx', '.tsx', '.conf', '.ini', '.sql', '.md', '.txt'
]

# Ã‡Ä±ktÄ± dosyasÄ±nÄ±n adÄ±
CIKTI_DOSYASI = "proje_dokumu.md"

# ==========================================
# ğŸ› ï¸ FONKSÄ°YONLAR
# ==========================================

def dosya_icerigini_getir(yol):
    """Dosya iÃ§eriÄŸini okur ve Markdown kod bloÄŸu iÃ§inde dÃ¶ndÃ¼rÃ¼r."""
    try:
        with open(yol, 'r', encoding='utf-8') as f:
            icerik = f.read()
            
        uzanti = os.path.splitext(yol)[1].lstrip('.').lower()
        return f"\n```{(uzanti if uzanti else 'plaintext')}\n{icerik}\n```\n"
    except Exception as e:
        return f"\n> [OkunamadÄ±: {e}]\n"

def dizin_yapisi_getir(hedef_dizin):
    """Verilen yoldan baÅŸlayarak dizin yapÄ±sÄ±nÄ± dÃ¶ndÃ¼rÃ¼r."""
    yapÄ± = "### ğŸ“‚ Proje Dizin YapÄ±sÄ± ve Dosyalar\n\n"
    
    for kok, dizinler, dosyalar in os.walk(hedef_dizin):
        # Filtreleme: Gereksiz klasÃ¶rleri gezme
        dizinler[:] = [d for d in dizinler if d.lower() not in DIKKATE_ALINMAYACAK_DIZINLER]
        
        yol_parcalari = kok.lower().split(os.sep)
        if any(yasak in yol_parcalari for yasak in DIKKATE_ALINMAYACAK_DIZINLER):
            continue

        base_name = os.path.basename(kok)
        goreli_yol = os.path.relpath(kok, hedef_dizin)
        
        # AÄŸaÃ§ yapÄ±sÄ± baÅŸlÄ±ÄŸÄ±
        if goreli_yol == '.':
            seviye = 0
            yapÄ± += f"- **{os.path.basename(hedef_dizin)}/** (Proje KÃ¶kÃ¼)\n"
        else:
            seviye = goreli_yol.count(os.sep) + 1
            girinti = "  " * seviye
            
            # Ã–zel klasÃ¶r kontrolÃ¼ (my_projects gibi)
            if base_name in OZEL_USER_KLASORLERI:
                yapÄ± += f"{girinti}- **{base_name}/** (KullanÄ±cÄ± Projeleri - Ä°Ã§erik Gizli)\n"
                dizinler[:] = [] # AltÄ±na inme
                continue 
            else:
                yapÄ± += f"{girinti}- **{base_name}/**\n"

        girinti_dosya = "  " * (seviye + 1)
        
        # DOSYALARI LÄ°STELEME (Filtresiz)
        for dosya in sorted(dosyalar):
            # .git klasÃ¶rÃ¼ iÃ§indeki dosyalarÄ± hariÃ§ tut, gerisi gelsin
            if '.git' in yol_parcalari: continue
            
            yapÄ± += f"{girinti_dosya}- {dosya}\n"
                    
    return yapÄ±

def ana_fonksiyon():
    hedef_dizin = os.getcwd() 
    proje_adi = os.path.basename(hedef_dizin)
    
    dokum_metni = f"# ğŸ“ Proje DÃ¶kÃ¼mÃ¼: {proje_adi}\n\n"
    dokum_metni += f"Bu dÃ¶kÃ¼m, **{hedef_dizin}** dizini iÃ§in oluÅŸturulmuÅŸtur.\n"
    dokum_metni += "Not: `my_projects` klasÃ¶rÃ¼nÃ¼n iÃ§eriÄŸi gizlilik gereÄŸi hariÃ§ tutulmuÅŸtur.\n\n"
    
    print(f"1/3: '{proje_adi}' klasÃ¶r yapÄ±sÄ± taranÄ±yor...")
    dokum_metni += dizin_yapisi_getir(hedef_dizin)
    
    dokum_metni += "\n---\n"
    dokum_metni += "### ğŸ’» Kod Ä°Ã§eriÄŸi DÃ¶kÃ¼mÃ¼\n\n"
    
    print("2/3: Kod iÃ§erikleri toplanÄ±yor...")
    
    dosya_sayisi = 0
    for kok, dizinler, dosyalar in os.walk(hedef_dizin):
        dizinler[:] = [d for d in dizinler if d.lower() not in DIKKATE_ALINMAYACAK_DIZINLER]
        
        if os.path.basename(kok) in OZEL_USER_KLASORLERI:
            dizinler[:] = []
            continue

        yol_parcalari = kok.lower().split(os.sep)
        if any(yasak in yol_parcalari for yasak in DIKKATE_ALINMAYACAK_DIZINLER): continue

        for dosya in sorted(dosyalar):
            dosya_yolu = os.path.join(kok, dosya)
            
            # KENDÄ°SÄ°NÄ° VE Ã‡IKTI DOSYASINI OKUMASIN (Ä°Ã§erik DÃ¶kÃ¼mÃ¼nde)
            if dosya == CIKTI_DOSYASI: continue
            
            uzanti = os.path.splitext(dosya)[1].lower()

            if uzanti in BELGELENECEK_KOD_UZANTILARI:
                goreli_yol = os.path.relpath(dosya_yolu, hedef_dizin)
                dokum_metni += f"\n#### ğŸ“„ Dosya: `{goreli_yol}`\n"
                dokum_metni += dosya_icerigini_getir(dosya_yolu)
                dosya_sayisi += 1
            
    print(f"3/3: '{CIKTI_DOSYASI}' dosyasÄ±na kayÄ±t yapÄ±lÄ±yor...")
    try:
        cikti_yolu = os.path.join(hedef_dizin, CIKTI_DOSYASI)
        with open(cikti_yolu, 'w', encoding='utf-8') as f:
            f.write(dokum_metni)
        print(f"\nâœ… Ä°ÅŸlem BaÅŸarÄ±lÄ±! Toplam {dosya_sayisi} dosya belgelendi.")
    except Exception as e:
        print(f"\nâŒ Hata: {e}")
        
if __name__ == "__main__":
    ana_fonksiyon()
```

#### ğŸ“„ Dosya: `launcher.py`

```py
import os
import sys
import json
import time
import datetime
import importlib

# -----------------------------------------------------
# DÃœZELTME: core.py olmadÄ±ÄŸÄ± iÃ§in assistant.py kullanÄ±yoruz
# -----------------------------------------------------
try:
    import config
except ImportError:
    print("HATA: config.py dosyasÄ± bulunamadÄ±!")
    sys.exit(1)

# ==========================================
# AYARLAR VE TANIMLAMALAR
# ==========================================
MEMORY_OPTIONS = {
    "1": {"id": "all-MiniLM-L6-v2", "name": "Hafif (Light)", "desc": "ğŸš€ HÄ±zlÄ± | DÃ¼ÅŸÃ¼k RAM"},
    "2": {"id": "paraphrase-multilingual-MiniLM-L12-v2", "name": "Dengeli (Medium)", "desc": "âš–ï¸  Daha Ä°yi TÃ¼rkÃ§e"},
    "3": {"id": "all-mpnet-base-v2", "name": "GÃ¼Ã§lÃ¼ (Heavy)", "desc": "ğŸ§  YÃ¼ksek DoÄŸruluk"}
}

def clear_screen():
    os.system('cls' if os.name == 'nt' else 'clear')

def update_config_file(variable_name, new_value):
    try:
        with open("config.py", "r", encoding="utf-8") as f: lines = f.readlines()
        with open("config.py", "w", encoding="utf-8") as f:
            found = False
            for line in lines:
                if line.strip().startswith(variable_name):
                    f.write(f'{variable_name} = "{new_value}"\n'); found = True
                else: f.write(line)
            if not found: f.write(f'\n{variable_name} = "{new_value}"\n')
        return True
    except: return False

def load_projects():
    projects = []
    if not os.path.exists(config.PROJECTS_DIR):
        try: os.makedirs(config.PROJECTS_DIR)
        except: pass

    try: items = os.listdir(config.PROJECTS_DIR)
    except: items = []
    
    for item in items:
        path = os.path.join(config.PROJECTS_DIR, item)
        if os.path.isdir(path):
            meta_path = os.path.join(path, "metadata.json")
            embedding_model = "BÄ°LÄ°NMÄ°YOR"
            cost = 0.0
            last_date = "0"
            if os.path.exists(meta_path):
                try:
                    with open(meta_path, 'r') as f:
                        data = json.load(f)
                        embedding_model = data.get("embedding_model", "Eski")
                        cost = data.get("total_cost", 0.0)
                        last_date = data.get("last_interaction", "0")
                except: pass
            
            projects.append({"name": item, "embedding_model": embedding_model, "cost": cost, "last_date": last_date})
    return sorted(projects, key=lambda x: x['last_date'], reverse=True)

def create_new_project():
    print(f"\n{config.Colors.CYAN}âœ¨ Yeni Proje OluÅŸtur{config.Colors.RESET}")
    name = input("Proje Ä°smi: ").strip()
    if not name: return
    path = os.path.join(config.PROJECTS_DIR, name)
    if os.path.exists(path):
        print("Bu proje zaten var!"); time.sleep(1); return

    try:
        os.makedirs(path)
        metadata = {
            "created_at": str(datetime.datetime.now()),
            "embedding_model": config.EMBEDDING_MODEL,
            "total_cost": 0.0,
            "last_interaction": str(datetime.datetime.now())
        }
        with open(os.path.join(path, "metadata.json"), 'w') as f: json.dump(metadata, f, indent=4)
        start_project(name, config.EMBEDDING_MODEL)
    except Exception as e: print(f"Hata: {e}"); input("Enter...")

def start_project(name, project_embed_model):
    if project_embed_model != config.EMBEDDING_MODEL:
        print(f"\n{config.Colors.RED}â›” UYUMSUZLUK: Bu proje '{project_embed_model}' kullanÄ±yor.{config.Colors.RESET}")
        print("Ayarlardan hafÄ±za modelini deÄŸiÅŸtirmeniz gerek."); input("Enter..."); return

    print(f"\n{config.Colors.GREEN}ğŸš€ Sistem BaÅŸlatÄ±lÄ±yor...{config.Colors.RESET}")
    try:
        # BURASI KRÄ°TÄ°K DEÄÄ°ÅÄ°KLÄ°K: core yerine assistant import ediyoruz
        import assistant
        importlib.reload(assistant)
        assistant.main(name) # assistant.py iÃ§indeki yeni main fonksiyonunu Ã§aÄŸÄ±r
    except ImportError as e:
        print(f"\n{config.Colors.RED}HATA: assistant.py yÃ¼klenemedi!{config.Colors.RESET}\n{e}"); input("Enter...")
    except AttributeError:
        print(f"\n{config.Colors.RED}HATA: assistant.py iÃ§inde 'main' fonksiyonu yok!{config.Colors.RESET}"); input("Enter...")
    except Exception as e:
        print(f"\nERROR: {e}"); input("Enter...")

def settings_menu():
    while True:
        clear_screen()
        print(f"{config.Colors.YELLOW}=== AYARLAR ==={config.Colors.RESET}")
        print(f"Aktif: {config.Colors.GREEN}{config.EMBEDDING_MODEL}{config.Colors.RESET}\n")
        for k, v in MEMORY_OPTIONS.items():
            mark = " (AKTÄ°F)" if v['id'] == config.EMBEDDING_MODEL else ""
            print(f"[{k}] {v['name']}{mark} -> {v['id']}")
        sel = input("\nSeÃ§im ([X] Ä°ptal): ").strip().upper()
        if sel == 'X': break
        if sel in MEMORY_OPTIONS:
            new_val = MEMORY_OPTIONS[sel]['id']
            if new_val != config.EMBEDDING_MODEL:
                update_config_file("EMBEDDING_MODEL", new_val)
                print("â™»ï¸  Yeniden baÅŸlatÄ±lÄ±yor..."); time.sleep(1)
                os.execv(sys.executable, ['python'] + sys.argv)

def main():
    while True:
        clear_screen()
        importlib.reload(config)
        projects = load_projects()
        
        print(f"{config.Colors.BOLD}{config.Colors.BLUE}=== AI ASÄ°STAN (v2.3) ==={config.Colors.RESET}")
        print(f"ğŸ§  HafÄ±za: {config.Colors.YELLOW}{config.EMBEDDING_MODEL}{config.Colors.RESET}")
        print("-" * 60)
        
        for idx, p in enumerate(projects, 1):
            compatible = (p['embedding_model'] == config.EMBEDDING_MODEL)
            status = "âœ…" if compatible else "â›”"
            print(f"[{idx}] {p['name']:<15} {status} ({p['embedding_model']})")
            
        print("-" * 60)
        print("[N] Yeni Proje  |  [S] Ayarlar  |  [Q] Ã‡Ä±kÄ±ÅŸ")
        ch = input("> ").strip().upper()
        
        if ch == 'Q': sys.exit()
        elif ch == 'N': create_new_project()
        elif ch == 'S': settings_menu()
        elif ch.isdigit():
            idx = int(ch) - 1
            if 0 <= idx < len(projects): start_project(projects[idx]['name'], projects[idx]['embedding_model'])

if __name__ == "__main__":
    main()
```

#### ğŸ“„ Dosya: `migrate_projects.py`

```py
import os
import shutil
from pathlib import Path

# Hedef
TARGET_DIR = Path("my_projects")
if not TARGET_DIR.exists():
    os.makedirs(TARGET_DIR)

print("ğŸšš Proje TaÅŸÄ±ma Ä°ÅŸlemi BaÅŸlÄ±yor...")

# Mevcut dizindeki klasÃ¶rleri tara
for entry in Path.cwd().iterdir():
    # Kendi dizinimizdeki klasÃ¶rler (my_projects hariÃ§)
    if entry.is_dir() and entry.name != "my_projects" and entry.name != "core" and entry.name != "venv" and not entry.name.startswith("."):
        
        # EÄŸer iÃ§inde .coder_memory varsa bu bir projedir!
        if (entry / ".coder_memory").exists():
            print(f"ğŸ“¦ Bulundu ve TaÅŸÄ±nÄ±yor: {entry.name}")
            try:
                shutil.move(str(entry), str(TARGET_DIR / entry.name))
                print(f"   âœ… TaÅŸÄ±ndÄ±.")
            except Exception as e:
                print(f"   âŒ Hata: {e}")

print("\nğŸ Ä°ÅŸlem Tamam. ArtÄ±k launcher.py'yi Ã§alÄ±ÅŸtÄ±rabilirsiniz.")
```

#### ğŸ“„ Dosya: `model_selector.py`

```py
# model_selector.py
import os
from config import Colors, MODEL_CONFIGS

def check_api_key(env_var):
    """Ortam deÄŸiÅŸkeninde API anahtarÄ± var mÄ± kontrol eder."""
    key = os.getenv(env_var)
    return key is not None and len(key) > 0

def get_available_models():
    """Sistemdeki kullanÄ±labilir modelleri dinamik olarak tarar."""
    available = {}
    
    # 1. Gemini KontrolÃ¼
    gemini_conf = MODEL_CONFIGS["gemini"]
    if check_api_key(gemini_conf["env_var"]):
        try:
            from core.gemini import GeminiModel
            available["1"] = {
                "class": GeminiModel,
                "name": gemini_conf["display_name"],
                "status": f"{Colors.GREEN}âœ… HazÄ±r{Colors.RESET}"
            }
        except ImportError:
            available["1"] = {"status": f"{Colors.RED}âŒ KÃ¼tÃ¼phane eksik (google-genai){Colors.RESET}"}
    else:
        available["1"] = {
            "name": gemini_conf["display_name"],
            "status": f"{Colors.RED}âŒ API Key Eksik ({gemini_conf['env_var']}){Colors.RESET}"
        }

    # 2. Hugging Face KontrolÃ¼
    hf_conf = MODEL_CONFIGS["huggingface"]
    if check_api_key(hf_conf["env_var"]):
        try:
            from core.huggingface import HuggingFaceModel
            available["2"] = {
                "class": HuggingFaceModel,
                "name": hf_conf["display_name"],
                "status": f"{Colors.GREEN}âœ… HazÄ±r{Colors.RESET}"
            }
        except ImportError:
             available["2"] = {"status": f"{Colors.RED}âŒ KÃ¼tÃ¼phane eksik (requests){Colors.RESET}"}
    else:
        available["2"] = {
            "name": hf_conf["display_name"],
            "status": f"{Colors.RED}âŒ API Key Eksik ({hf_conf['env_var']}){Colors.RESET}"
        }

    return available

def select_model_interactive():
    """KullanÄ±cÄ±ya interaktif seÃ§im menÃ¼sÃ¼ sunar."""
    available = get_available_models()
    
    print(f"\n{Colors.BLUE}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print(f"â•‘       ğŸ¤–  AI MODEL SEÃ‡Ä°M EKRANI        â•‘")
    print(f"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{Colors.RESET}\n")

    ready_models = {}
    
    for key, info in available.items():
        # EÄŸer 'class' anahtarÄ± varsa model Ã§alÄ±ÅŸtÄ±rÄ±labilir demektir
        if "class" in info:
            ready_models[key] = info["class"]
            print(f"  [{key}] {info['name']}  {info['status']}")
        else:
            print(f"  [{key}] {info.get('name', 'Bilinmeyen')}  {info['status']}")

    if not ready_models:
        print(f"\n{Colors.RED}âš ï¸  HÄ°Ã‡BÄ°R MODEL KULLANILABÄ°LÄ°R DURUMDA DEÄÄ°L!{Colors.RESET}")
        print(f"{Colors.YELLOW}LÃ¼tfen .bashrc dosyasÄ±na API anahtarlarÄ±nÄ±zÄ± ekleyin.{Colors.RESET}")
        return None

    # VarsayÄ±lan olarak ilk hazÄ±r modeli seÃ§
    default_key = list(ready_models.keys())[0]
    
    print(f"\n{Colors.CYAN}VarsayÄ±lan Model: {available[default_key]['name']} (Enter'a bas){Colors.RESET}")
    choice = input(f"{Colors.YELLOW}SeÃ§iminiz [1/2]: {Colors.RESET}").strip()
    
    if not choice:
        choice = default_key
        
    if choice in ready_models:
        try:
            return ready_models[choice]()
        except Exception as e:
            print(f"{Colors.RED}Model baÅŸlatÄ±lÄ±rken hata oluÅŸtu: {e}{Colors.RESET}")
            return None
    else:
        print(f"{Colors.RED}GeÃ§ersiz seÃ§im.{Colors.RESET}")
        return None
```

#### ğŸ“„ Dosya: `readme.md`

```md
# ğŸš€ Coder-Asistan
### HafÄ±zalÄ±, GÃ¼venli ve Proje OdaklÄ± AI Kodlama StÃ¼dyosu

![Python](https://img.shields.io/badge/python-3.10%2B-blue)
![License](https://img.shields.io/badge/license-MIT-green)
![Status](https://img.shields.io/badge/status-active-success)

**Coder-Asistan**, klasik "soru sor â€“ cevap al" botlarÄ±ndan farklÄ± olarak, projelerinizi yÃ¶neten, baÄŸlamÄ± hatÄ±rlayan ve kodu **kontrollÃ¼ ÅŸekilde** deÄŸiÅŸtiren **terminal tabanlÄ± bir AI geliÅŸtirme ortamÄ±dÄ±r.**

Her proje iÃ§in ayrÄ± bir hafÄ±za oluÅŸturur (RAG). Bir projede Ã¶ÄŸrendiÄŸini diÄŸerine taÅŸÄ±maz. Ne yaptÄ±ÄŸÄ±nÄ± Ã¶nce planlar, sonra siz onaylarsanÄ±z uygular.

> **KÄ±saca:** Bu bir bot deÄŸil, **AI destekli bir geliÅŸtirme Ã§alÄ±ÅŸma alanÄ±**.

---

## ğŸ¯ Temel Ã–zellikler

* **ğŸ­ Proje FabrikasÄ± (`launcher.py`):** TÃ¼m projeleri tek merkezden yÃ¶netin.
* **ğŸ§  Ä°zole HafÄ±za:** Her projenin kendi `.coder_memory` klasÃ¶rÃ¼ vardÄ±r. AI, projenizdeki dosyalarÄ± okur ve hatÄ±rlar.
* **ğŸ›¡ï¸ GÃ¼venli Mod:** KodlarÄ± doÄŸrudan yazmaz; Ã¶nce plan sunar, onaylarsanÄ±z iÅŸler.
* **ğŸ’° Maliyet Takibi:** Token baÅŸÄ±na harcamayÄ± kuruÅŸu kuruÅŸuna raporlar.
* **ğŸ”Œ Model Ã–zgÃ¼rlÃ¼ÄŸÃ¼:** Google Gemini, Llama 3 (Groq), DeepSeek veya Hugging Face.

---

## ğŸ“¦ Kurulum (2 Dakikada HazÄ±r)

### 1ï¸âƒ£ Projeyi Ä°ndirin
```bash
git clone [https://github.com/cetincevizcetoli/coder-asistan.git](https://github.com/cetincevizcetoli/coder-asistan.git)
cd coder-asistan
```

### 2ï¸âƒ£ Sanal Ortam OluÅŸturun (Ã–NEMLÄ°)

**ğŸªŸ Windows:**
```cmd
python -m venv venv
venv\Scripts\activate
```

**ğŸ§ Linux / macOS:**
```bash
python3 -m venv venv
source venv/bin/activate
```
*(Terminal satÄ±rÄ±nÄ±n baÅŸÄ±nda `(venv)` yazÄ±sÄ±nÄ± gÃ¶rmelisiniz.)*

### 3ï¸âƒ£ Paketleri YÃ¼kleyin
```bash
pip install -r requirements.txt
```

---

## ğŸ”‘ API AnahtarÄ± AyarlarÄ±

Coder-Asistan bir beyne ihtiyaÃ§ duyar. **Google Gemini (Ãœcretsiz)** Ã¶nerilir.

1. [Google AI Studio](https://aistudio.google.com/app/apikey) adresinden Key alÄ±n.
2. BilgisayarÄ±nÄ±za kaydedin:

**ğŸªŸ Windows (KalÄ±cÄ±):**
```cmd
setx GOOGLE_API_KEY "API_KEY_BURAYA_YAPISTIR"
```
*(Komuttan sonra terminali kapatÄ±p yeniden aÃ§Ä±n!)*

**ğŸ§ Linux / macOS:**
```bash
echo 'export GOOGLE_API_KEY="API_KEY_BURAYA"' >> ~/.bashrc
source ~/.bashrc
```

---

## â–¶ï¸ NasÄ±l KullanÄ±lÄ±r? (Ana Kumanda)

TÃ¼m sistemi yÃ¶netmek iÃ§in tek bir komut yeterlidir:

```bash
python launcher.py
```

KarÅŸÄ±nÄ±za gelen menÃ¼den:
* **[N]** ile yeni proje oluÅŸturabilir,
* **[1-9]** ile mevcut projelerinize girip AI ile Ã§alÄ±ÅŸmaya baÅŸlayabilirsiniz.
* **[E]** ile projelerinizi ZIP olarak yedekleyebilirsiniz.

---

## ğŸ› ï¸ Ä°sviÃ§re Ã‡akÄ±sÄ±: YardÄ±mcÄ± AraÃ§lar

Bu projede sadece kod yazan bir asistan yok, iÅŸinizi kolaylaÅŸtÄ±racak bir dizi **profesyonel araÃ§** bulunur. Ä°ÅŸte alet Ã§antanÄ±z:

### 1. ğŸ•µï¸â€â™‚ï¸ HafÄ±za MÃ¼fettiÅŸi (`debug.py`)
AI'nÄ±n projeniz hakkÄ±nda ne bildiÄŸini merak mÄ± ediyorsunuz? VektÃ¶r veritabanÄ±nÄ±n iÃ§ine girip kaydedilen kod parÃ§alarÄ±nÄ± okumanÄ±zÄ± saÄŸlar.
```bash
python debug.py
```
* **Ne zaman kullanÄ±lÄ±r?** AI, kodunuzu hatÄ±rlamÄ±yorsa veya yanlÄ±ÅŸ cevap veriyorsa hafÄ±zayÄ± kontrol etmek iÃ§in.

### 2. ğŸšš Proje Nakliyecisi (`migrate_projects.py`)
Eski sÃ¼rÃ¼mden kalma veya yanlÄ±ÅŸlÄ±kla ana dizine kopyaladÄ±ÄŸÄ±nÄ±z projeleri bulur ve otomatik olarak yeni sisteme (`my_projects` klasÃ¶rÃ¼ne) taÅŸÄ±r.
```bash
python migrate_projects.py
```
* **Ne zaman kullanÄ±lÄ±r?** KlasÃ¶rde projeniz var ama Launcher listesinde gÃ¶rÃ¼nmÃ¼yorsa.

### 3. ğŸ©º Sistem Doktoru (`system_audit.py`)
Projelerinizin saÄŸlÄ±k kontrolÃ¼nÃ¼ yapar. Log dosyalarÄ± dolu mu? VeritabanÄ± bÃ¼tÃ¼nlÃ¼ÄŸÃ¼ (integrity) saÄŸlam mÄ±? Hepsini raporlar.
```bash
python system_audit.py
```
* **Ne zaman kullanÄ±lÄ±r?** Sistemsel bir hatadan ÅŸÃ¼pheleniyorsanÄ±z veya veritabanÄ± bozulduysa.

### 4. ğŸ“ Proje Katibi (`generate_docs.py`)
TÃ¼m projenizin kodlarÄ±nÄ± okur ve tek bir Markdown dosyasÄ±nda (`proje_dokumu.md`) birleÅŸtirir.
```bash
python generate_docs.py
```
* **Ne zaman kullanÄ±lÄ±r?** Projenin tamamÄ±nÄ± ChatGPT/Claude gibi baÅŸka bir AI'ya atÄ±p "Bunu analiz et" demek istediÄŸinizde.

### 5. ğŸ“¡ Model KontrolcÃ¼sÃ¼ (`check_models.py`)
Google hesabÄ±nÄ±zda tanÄ±mlÄ± ve eriÅŸilebilir olan Gemini modellerini listeler.
```bash
python check_models.py
```
* **Ne zaman kullanÄ±lÄ±r?** "Hangi modelleri kullanabilirim?" diye merak ettiÄŸinizde.

---

## ğŸ§ª GeliÅŸmiÅŸ Parametreler

Projeye girdikten sonra (veya `assistant.py`'yi manuel kullanÄ±rken) ÅŸu modlarÄ± kullanabilirsiniz:

* **`--dry-run` (Prova Modu):**
  AI kodlarÄ± yazar, planÄ± gÃ¶sterir ama **dosyaya kaydetmez.**
  ```bash
  python assistant.py "Ana sayfayÄ± deÄŸiÅŸtir" --dry-run
  ```

* **`--verbose` (Geveze Mod):**
  Arka planda dÃ¶nen ham JSON verisini ve dÃ¼ÅŸÃ¼nce sÃ¼recini gÃ¶sterir. Hata ayÄ±klamak iÃ§in idealdir.
  ```bash
  python assistant.py "Hata bul" --verbose
  ```

---

## ğŸ—ï¸ Proje Mimarisi

```text
coder-asistan/
â”œâ”€ launcher.py          # ğŸ® ANA KUMANDA (BaÅŸlatÄ±cÄ±)
â”œâ”€ assistant.py         # ğŸ§  Ä°ÅŸlem Motoru
â”œâ”€ my_projects/         # ğŸ“‚ PROJE FABRÄ°KASI
â”‚  â””â”€ odev-1/           # ğŸ”’ Ä°zole Proje AlanÄ±
â”‚     â”œâ”€ .coder_memory/ # ğŸ§  Projeye Ã¶zel hafÄ±za
â”‚     â””â”€ src/           # KodlarÄ±nÄ±z
â”œâ”€ debug.py             # ğŸ•µï¸â€â™‚ï¸ HafÄ±za MÃ¼fettiÅŸi
â”œâ”€ system_audit.py      # ğŸ©º Sistem Doktoru
â”œâ”€ migrate_projects.py  # ğŸšš TaÅŸÄ±yÄ±cÄ±
â””â”€ requirements.txt
```

---

## ğŸ’¡ Ä°puÃ§larÄ± ve PÃ¼f NoktalarÄ±

* **ğŸ—‘ï¸ Proje Silme:** Bir projeyi silmek iÃ§in Launcher'da bir komut yoktur. `my_projects` klasÃ¶rÃ¼ne gidip ilgili proje klasÃ¶rÃ¼nÃ¼ **elle silmeniz** yeterlidir.
* **ğŸ§  HafÄ±za SÄ±fÄ±rlama:** AI eski kodlarÄ± hatÄ±rlamakta Ä±srar ediyorsa veya kafasÄ± karÄ±ÅŸtÄ±ysa; proje klasÃ¶rÃ¼nÃ¼zdeki `.coder_memory` klasÃ¶rÃ¼nÃ¼ silin. Coder-Asistan bir sonraki aÃ§Ä±lÄ±ÅŸta dosyalarÄ± tarayÄ±p hafÄ±zayÄ± sÄ±fÄ±rdan kuracaktÄ±r.
* **âš™ï¸ Ä°nce Ayarlar:** Dosya boyutu sÄ±nÄ±rlarÄ±nÄ± veya maliyet hesaplama yÃ¶ntemini deÄŸiÅŸtirmek isterseniz `config.py` dosyasÄ±nÄ± dÃ¼zenleyebilirsiniz.

---
## ğŸ¤ KatkÄ±da Bulunma

Pull request'ler kabul edilir! BÃ¼yÃ¼k deÄŸiÅŸiklikler iÃ§in Ã¶nce bir Issue aÃ§arak tartÄ±ÅŸalÄ±m.

> ğŸ—ï¸ **GeliÅŸtirici Notu:** Bu projenin iÃ§ yapÄ±sÄ±nÄ±, veri akÄ±ÅŸÄ±nÄ± ve teknik detaylarÄ±nÄ± derinlemesine incelemek iÃ§in lÃ¼tfen **[MÄ°MARÄ° VE TEKNÄ°K KILAVUZ (ARCHITECTURE.md)](ARCHITECTURE.md)** dosyasÄ±nÄ± okuyunuz.
---
## ğŸ‘¤ GeliÅŸtirici

**Ahmet Ã‡etin**
* **GitHub:** [github.com/cetincevizcetoli](https://github.com/cetincevizcetoli)
* **Web:** [yapanzeka.acetin.com.tr](https://yapanzeka.acetin.com.tr)

> *"KarmaÅŸÄ±k kodlarÄ±, kontrollÃ¼ araÃ§larla yÃ¶netin."*
```

#### ğŸ“„ Dosya: `requirements.txt`

```txt
google-genai
requests
# --- RAG ve HafÄ±za ---
chromadb>=0.4.0
sentence-transformers>=2.2.0
torch>=2.0.0
# --- YardÄ±mcÄ±lar ---
tqdm  # Ä°ndeksleme sÄ±rasÄ±nda progress bar iÃ§in (opsiyonel ama iyi pratik)
```

#### ğŸ“„ Dosya: `settings_menu.py`

```py
import os
import json
import time

# Renkler
GREEN = '\033[92m'
RED = '\033[91m'
YELLOW = '\033[93m'
CYAN = '\033[96m'
RESET = '\033[0m'

SETTINGS_FILE = "user_settings.json"

# HafÄ±za Profilleri
PROFILES = {
    'light':  {'name': 'Hafif (Light)',  'size': '80 MB',  'desc': 'ğŸš€ Ã‡ok HÄ±zlÄ±, DÃ¼ÅŸÃ¼k RAM (Z570 Ä°Ã§in Ã–nerilen)'},
    'medium': {'name': 'Orta (Medium)',  'size': '470 MB', 'desc': 'âš–ï¸ Daha Ä°yi TÃ¼rkÃ§e, Dengeli HÄ±z'},
    'heavy':  {'name': 'AÄŸÄ±r (Heavy)',   'size': '2.2 GB', 'desc': 'ğŸ‹ï¸ Ã‡ok YavaÅŸ, GPU Ä°ster (Dikkat!)'}
}

def load_settings():
    if os.path.exists(SETTINGS_FILE):
        try:
            with open(SETTINGS_FILE, 'r') as f:
                return json.load(f)
        except: pass
    return {"active_profile": "light"}

def save_settings(settings):
    try:
        with open(SETTINGS_FILE, 'w') as f:
            json.dump(settings, f, indent=4)
    except Exception as e:
        print(f"{RED}Ayarlar kaydedilemedi: {e}{RESET}")

def settings_main():
    while True:
        os.system('cls' if os.name == 'nt' else 'clear')
        current_settings = load_settings()
        curr_profile = current_settings.get("active_profile", "light")
        
        if curr_profile not in PROFILES:
            curr_profile = 'light'

        print(f"{CYAN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—{RESET}")
        print(f"{CYAN}â•‘           âš™ï¸  SÄ°STEM AYARLARI                 â•‘{RESET}")
        print(f"{CYAN}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{RESET}")
        
        p_info = PROFILES[curr_profile]
        
        print(f"\nğŸ§  Aktif HafÄ±za Modeli: {GREEN}{p_info['name']} [{p_info['size']}]{RESET}")
        print(f"{YELLOW}   â””â”€ {p_info['desc']}{RESET}\n")
        
        print("Mevcut SeÃ§enekler:")
        print(f"   [1] Hafif  (80 MB)  - HÄ±z OdaklÄ±")
        print(f"   [2] Orta   (470 MB) - Anlama OdaklÄ±")
        print(f"   [3] AÄŸÄ±r   (2 GB)   - Detay OdaklÄ±")
        print(f"\n   [Q] MenÃ¼ye DÃ¶n")
        
        choice = input(f"\n{YELLOW}SeÃ§iminiz: {RESET}").strip().lower()
        
        if choice == 'q':
            break
            
        new_profile = None
        if choice == '1': new_profile = 'light'
        elif choice == '2': new_profile = 'medium'
        elif choice == '3': new_profile = 'heavy'
        
        if new_profile and new_profile != curr_profile:
            print(f"\n{RED}âš ï¸  DÄ°KKAT: HafÄ±za Modeli DeÄŸiÅŸtiriliyor!{RESET}")
            print(f"Eski model ile oluÅŸturulan proje hafÄ±zalarÄ±, bu model ile Ã§alÄ±ÅŸmaz.")
            print(f"Sistem, projeye girdiÄŸinde eski hafÄ±zayÄ± otomatik olarak {RED}ARÅÄ°VLEYÄ°P SIFIRLAYACAKTIR.{RESET}")
            
            # --- DÃœZELTME BURADA ---
            # ArtÄ±k hem 'evet' hem 'e' kabul ediyor
            confirm = input(f"\n{RED}OnaylÄ±yor musunuz? (e/h): {RESET}").lower()
            
            if confirm in ['evet', 'e']:
                current_settings["active_profile"] = new_profile
                save_settings(current_settings)
                print(f"\n{GREEN}âœ… Ayar deÄŸiÅŸtirildi: {new_profile.upper()}{RESET}")
                time.sleep(1.5)
            else:
                print(f"\n{YELLOW}Ä°ptal edildi.{RESET}")
                time.sleep(1)
        elif new_profile == curr_profile:
            print(f"\n{YELLOW}Zaten bu mod aktif.{RESET}")
            time.sleep(1)

if __name__ == "__main__":
    settings_main()
```

#### ğŸ“„ Dosya: `system_audit.py`

```py
import os
import sys
import sqlite3
from pathlib import Path

# Config dosyasÄ±ndan proje klasÃ¶rÃ¼nÃ¼ Ã¶ÄŸrenelim
try:
    import config
    PROJECTS_DIR_NAME = config.PROJECTS_DIR
except ImportError:
    PROJECTS_DIR_NAME = "my_projects"

# Renkler
GREEN = '\033[92m'
RED = '\033[91m'
YELLOW = '\033[93m'
RESET = '\033[0m'
CYAN = '\033[96m'

def check_file_exists(path, description):
    if os.path.exists(path):
        size = os.path.getsize(path)
        print(f"{GREEN}âœ… {description} Mevcut ({size} bytes){RESET}")
        return True
    else:
        print(f"{RED}âŒ {description} BULUNAMADI! ({path}){RESET}")
        return False

def audit_log_file(project_path):
    log_path = project_path / ".chat_history.log"
    print(f"\n--- ğŸ“œ LOG DOSYASI KONTROLÃœ ({log_path.name}) ---")
    
    if check_file_exists(log_path, "Log DosyasÄ±"):
        try:
            with open(log_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                print(f"   ğŸ“„ Toplam SatÄ±r: {len(lines)}")
                if len(lines) > 0:
                    print(f"   ğŸ” Son KayÄ±t: {lines[-2].strip() if len(lines) > 1 else lines[0].strip()}")
                else:
                    print(f"{YELLOW}   âš ï¸ Dosya var ama iÃ§i boÅŸ.{RESET}")
        except Exception as e:
            print(f"{RED}   âŒ Dosya okuma hatasÄ±: {e}{RESET}")

def audit_vector_db(project_path):
    db_path = project_path / ".coder_memory"
    sqlite_file = db_path / "chroma.sqlite3"
    
    print(f"\n--- ğŸ§  VEKTÃ–R VERÄ°TABANI KONTROLÃœ ---")
    
    if not os.path.exists(db_path):
        print(f"{RED}âŒ .coder_memory klasÃ¶rÃ¼ yok (HafÄ±zasÄ±z Proje).{RESET}")
        return

    if check_file_exists(sqlite_file, "ChromaDB SQLite DosyasÄ±"):
        try:
            # ChromaDB kÃ¼tÃ¼phanesini kullanmadan direkt SQL ile bÃ¼tÃ¼nlÃ¼k testi
            conn = sqlite3.connect(sqlite_file)
            cursor = conn.cursor()
            
            # TablolarÄ± say
            cursor.execute("SELECT count(*) FROM sqlite_master WHERE type='table';")
            tables = cursor.fetchone()[0]
            print(f"   ğŸ“Š Tablo SayÄ±sÄ±: {tables}")
            
            # Embedding sayÄ±sÄ±nÄ± bulmaya Ã§alÄ±ÅŸ
            try:
                # Chroma versiyonuna gÃ¶re tablo adÄ± deÄŸiÅŸebilir, genelde 'embeddings'
                cursor.execute("SELECT count(*) FROM embeddings;")
                count = cursor.fetchone()[0]
                print(f"   ğŸ§¬ Ä°ndekslenmiÅŸ VektÃ¶r SayÄ±sÄ±: {GREEN}{count}{RESET}")
            except:
                print(f"{YELLOW}   âš ï¸ 'embeddings' tablosu direkt okunamadÄ± (Versiyon farkÄ± olabilir).{RESET}")
                
            conn.close()
            print(f"{GREEN}   âœ… VeritabanÄ± bÃ¼tÃ¼nlÃ¼ÄŸÃ¼ (Integrity) saÄŸlam.{RESET}")
            
        except Exception as e:
            print(f"{RED}   âŒ VeritabanÄ± bozuk veya okunamÄ±yor: {e}{RESET}")

def main():
    # DÃœZELTME: ArtÄ±k kÃ¶k dizine deÄŸil, my_projects iÃ§ine bakÄ±yoruz
    workspace = Path.cwd() / PROJECTS_DIR_NAME
    
    if not workspace.exists():
        print(f"{RED}Hata: '{PROJECTS_DIR_NAME}' klasÃ¶rÃ¼ bulunamadÄ±.{RESET}")
        return

    # Projeleri bul (iÃ§inde .coder_memory olan klasÃ¶rler)
    projects = [d for d in workspace.iterdir() if d.is_dir() and (d / ".coder_memory").exists()]
    
    print(f"{CYAN}ğŸ” SÄ°STEM DENETÃ‡Ä°SÄ° BAÅLATILDI{RESET}")
    print(f"ğŸ“‚ Hedef Dizin: {workspace}")
    
    if not projects:
        print(f"{RED}Test edilecek proje bulunamadÄ±.{RESET}")
        return

    print(f"âœ… {len(projects)} adet proje tespit edildi.")
    
    for proj in projects:
        print(f"\n{YELLOW}========================================{RESET}")
        print(f"ğŸ“‚ PROJE DENETLENÄ°YOR: {proj.name}")
        print(f"{YELLOW}========================================{RESET}")
        
        audit_log_file(proj)
        audit_vector_db(proj)

if __name__ == "__main__":
    main()
```

#### ğŸ“„ Dosya: `user_settings.json`

```json
{
    "active_profile": "medium"
}
```

#### ğŸ“„ Dosya: `core/base.py`

```py
# core/base.py: Ortak ArayÃ¼z ve Hata TanÄ±mlarÄ±

class ModelAPIError(Exception):
    """API baÄŸlantÄ±/kota hatalarÄ± iÃ§in genel hata sÄ±nÄ±fÄ±."""
    pass

class BaseModel:
    """TÃ¼m model sÄ±nÄ±flarÄ±nÄ±n miras alacaÄŸÄ± soyut sÄ±nÄ±f."""
    MODEL_NAME = "Temel Model"

    def __init__(self):
        # API anahtarÄ±nÄ± kontrol etme vb.
        pass

    def generate_content(self, system_instruction, prompt_text):
        """AI'dan iÃ§erik Ã¼retme Ã§aÄŸrÄ±sÄ±."""
        raise NotImplementedError("Bu metot alt sÄ±nÄ±flar tarafÄ±ndan uygulanmalÄ±dÄ±r.")
```

#### ğŸ“„ Dosya: `core/deepseek.py`

```py
# core/deepseek.py
import os
import requests
from .base import BaseModel, ModelAPIError
from config import MODEL_CONFIGS

class DeepSeekModel(BaseModel):
    """DeepSeek API - Ãœcretsiz ve gÃ¼Ã§lÃ¼"""
    
    def __init__(self):
        conf = MODEL_CONFIGS["deepseek"]
        self.MODEL_NAME = conf["display_name"]
        
        self.api_key = os.getenv(conf["env_var"])
        if not self.api_key:
            raise ModelAPIError(f"{conf['env_var']} ortam deÄŸiÅŸkeni bulunamadÄ±.")
        
        # DeepSeek OpenAI uyumlu API uÃ§ noktasÄ±
        self.api_url = "https://api.deepseek.com/v1/chat/completions"
        self.model_id = conf["model_id"]
    
    def generate_content(self, system_instruction, prompt_text):
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.model_id,
            "messages": [
                {"role": "system", "content": system_instruction},
                {"role": "user", "content": prompt_text}
            ],
            "temperature": 0.1,
            "max_tokens": 8000,
            "response_format": {"type": "json_object"}  # JSON zorla
        }
        
        try:
            response = requests.post(self.api_url, headers=headers, json=payload, timeout=60)
            response.raise_for_status()
            result = response.json()
            
            # Debug iÃ§in
            if hasattr(self, 'DEBUG') and self.DEBUG:
                print(f"DEBUG DeepSeek Response: {result}")
                
            return result["choices"][0]["message"]["content"].strip()
            
        except requests.exceptions.RequestException as e:
            # Hata mesajÄ±nÄ± daha detaylÄ± gÃ¶rmek iÃ§in
            if hasattr(e, 'response') and e.response is not None:
                error_msg = e.response.text
                print(f"DEBUG DeepSeek Error: {error_msg}")
                try:
                    error_json = json.loads(error_msg)
                    raise ModelAPIError(f"DeepSeek HatasÄ±: {error_json.get('message', str(e))}")
                except:
                    raise ModelAPIError(f"DeepSeek API HatasÄ±: {e}")
            else:
                raise ModelAPIError(f"DeepSeek BaÄŸlantÄ± HatasÄ±: {e}")
        except Exception as e:
            raise ModelAPIError(f"DeepSeek Ä°ÅŸlem HatasÄ±: {e}")
```

#### ğŸ“„ Dosya: `core/gemini.py`

```py
import os
from google import genai
from google.genai import types
from .base import BaseModel, ModelAPIError
from config import MODEL_CONFIGS

class GeminiModel(BaseModel):
    def __init__(self):
        conf = MODEL_CONFIGS["gemini"]
        self.MODEL_NAME = conf["display_name"]
        self.raw_model_name = conf["model_name"] # Fiyat hesaplamasÄ± iÃ§in
        
        api_key = os.getenv(conf["env_var"])
        if not api_key:
            raise ModelAPIError(f"{conf['env_var']} bulunamadÄ±.")

        try:
            self.client = genai.Client(api_key=api_key)
        except Exception as e:
            raise ModelAPIError(f"Gemini Client BaÅŸlatÄ±lamadÄ±: {e}")

    def generate_content(self, system_instruction, prompt_text):
        try:
            response = self.client.models.generate_content(
                model=self.raw_model_name,
                contents=[prompt_text],
                config=types.GenerateContentConfig(
                    system_instruction=system_instruction,
                    temperature=0.1
                )
            )
            
            # Token kullanÄ±mÄ±nÄ± gÃ¼venli ÅŸekilde al
            usage = {
                "input_tokens": 0,
                "output_tokens": 0
            }
            
            if hasattr(response, 'usage_metadata'):
                usage["input_tokens"] = response.usage_metadata.prompt_token_count
                usage["output_tokens"] = response.usage_metadata.candidates_token_count

            return {
                "content": response.text.strip(),
                "usage": usage,
                "model_key": self.raw_model_name
            }

        except Exception as e:
            raise ModelAPIError(f"Gemini HatasÄ±: {e}")
```

#### ğŸ“„ Dosya: `core/groq.py`

```py
# core/groq.py (DOÄRU VERSÄ°YON)
import os
import requests
from .base import BaseModel, ModelAPIError
from config import MODEL_CONFIGS

class GroqModel(BaseModel):
    """Groq LPU - Ultra hÄ±zlÄ± inference"""
    
    def __init__(self):
        conf = MODEL_CONFIGS["groq"]
        self.MODEL_NAME = conf["display_name"]
        
        # âš ï¸ Buradaki atamalarÄ±n doÄŸru yapÄ±ldÄ±ÄŸÄ±ndan emin olun:
        self.api_key = os.getenv(conf["env_var"])
        if not self.api_key:
            raise ModelAPIError(f"{conf['env_var']} ortam deÄŸiÅŸkeni bulunamadÄ±.")
        
        self.api_url = "https://api.groq.com/openai/v1/chat/completions"
        self.model_id = conf["model_id"]
    
    def generate_content(self, system_instruction, prompt_text):
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.model_id,
            "messages": [
                {"role": "system", "content": system_instruction},
                {"role": "user", "content": prompt_text}
            ],
            "temperature": 0.1,
            "max_tokens": 8000,
            "response_format": {"type": "json_object"}  # JSON zorla
        }
        
        try:
            response = requests.post(self.api_url, headers=headers, json=payload, timeout=30)
            response.raise_for_status()
            result = response.json()
            return result["choices"][0]["message"]["content"].strip()
        except Exception as e:
            # Hata mesajÄ±nÄ± daha detaylÄ± gÃ¶rmek iÃ§in
            if hasattr(e, 'response') and e.response is not None:
                 print(f"DEBUG RESPONSE: {e.response.text}")
            raise ModelAPIError(f"Groq API HatasÄ±: {e}")
```

#### ğŸ“„ Dosya: `core/huggingface.py`

```py
# core/huggingface.py
import os
import requests
import json
from .base import BaseModel, ModelAPIError
from config import MODEL_CONFIGS

class HuggingFaceModel(BaseModel):
    def __init__(self):
        conf = MODEL_CONFIGS["huggingface"]
        self.MODEL_NAME = conf["display_name"]
        self.model_id = conf["model_id"]
        
        self.api_key = os.getenv(conf["env_var"])
        if not self.api_key:
            raise ModelAPIError(f"{conf['env_var']} bulunamadÄ±.")
        
        self.headers = {"Authorization": f"Bearer {self.api_key}"}
        self.api_url = f"https://router.huggingface.co/models/{self.model_id}"

    def generate_content(self, system_instruction, prompt_text):
        # --- PROMPT FORMATLAMA ---
        # Qwen ve modern modeller iÃ§in ChatML formatÄ± en iyisidir
        if "qwen" in self.model_id.lower():
            full_prompt = (
                f"<|im_start|>system\n{system_instruction}<|im_end|>\n"
                f"<|im_start|>user\n{prompt_text}<|im_end|>\n"
                f"<|im_start|>assistant\n"
            )
        elif "llama-3" in self.model_id.lower():
            full_prompt = (
                f"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n{system_instruction}<|eot_id|>\n"
                f"<|start_header_id|>user<|end_header_id|>\n{prompt_text}<|eot_id|>\n"
                f"<|start_header_id|>assistant<|end_header_id|>"
            )
        else:
            # VarsayÄ±lan (Mistral/Eski Llama)
            full_prompt = f"[INST] <<SYS>>\n{system_instruction}\n<</SYS>>\n{prompt_text} [/INST]"

        payload = {
            "inputs": full_prompt,
            "parameters": {
                "max_new_tokens": 4096, # Kod Ã¼retimi iÃ§in yÃ¼ksek token
                "temperature": 0.1,     # TutarlÄ±lÄ±k iÃ§in dÃ¼ÅŸÃ¼k sÄ±caklÄ±k
                "return_full_text": False
            }
        }

        try:
            response = requests.post(self.api_url, headers=self.headers, json=payload)
            response.raise_for_status()
            
            result = response.json()
            
            # Hugging Face API bazen liste, bazen dict dÃ¶ner
            if isinstance(result, list) and len(result) > 0:
                return result[0].get('generated_text', '').strip()
            elif isinstance(result, dict):
                return result.get('generated_text', '').strip()
            else:
                raise ModelAPIError(f"Beklenmeyen API yanÄ±t formatÄ±: {type(result)}")

        except Exception as e:
            raise ModelAPIError(f"HF API HatasÄ±: {e}")
```

#### ğŸ“„ Dosya: `core/memory.py`

```py
import os
import shutil
import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
import torch
import config
from config import Colors

class MemoryManager:
    def __init__(self, project_root: str):
        """
        Belirtilen proje dizini iÃ§in izole hafÄ±za yÃ¶neticisi.
        """
        self.project_root = project_root
        self.memory_path = os.path.join(project_root, config.MEMORY_DIR_NAME)
        
        # 1. DonanÄ±m AlgÄ±lama ve Embedding Modelini YÃ¼kleme
        self.device = self._detect_device()
        print(f"{Colors.MAGENTA}ğŸ§  HafÄ±za Motoru BaÅŸlatÄ±lÄ±yor... ({self.device}){Colors.RESET}")
        
        try:
            self.embedder = SentenceTransformer(config.EMBEDDING_MODEL, device=self.device)
        except Exception as e:
            print(f"{Colors.RED}Model yÃ¼kleme hatasÄ±, CPU'ya geÃ§iliyor: {e}{Colors.RESET}")
            self.embedder = SentenceTransformer(config.EMBEDDING_MODEL, device="cpu")

        # 2. ChromaDB Ä°stemcisini BaÅŸlatma (Persistent)
        os.makedirs(self.memory_path, exist_ok=True)
        self.client = chromadb.PersistentClient(path=self.memory_path)
        
        # Koleksiyonu al veya oluÅŸtur
        self.collection = self.client.get_or_create_collection(
            name=config.COLLECTION_NAME,
            metadata={"hnsw:space": "cosine"} # Kod benzerliÄŸi iÃ§in kosinÃ¼s idealdir
        )

    def _detect_device(self) -> str:
        """Sistemi tarar: NVIDIA GPU -> Apple Silicon (MPS) -> CPU"""
        if torch.cuda.is_available():
            return "cuda"
        elif torch.backends.mps.is_available():
            return "mps"
        else:
            return "cpu"

    def index_files(self, file_paths: list):
        """DosyalarÄ± okur, vektÃ¶rleÅŸtirir ve veritabanÄ±na kaydeder."""
        documents = []
        metadatas = []
        ids = []

        print(f"{Colors.CYAN}ğŸ“¥ {len(file_paths)} dosya indeksleniyor...{Colors.RESET}")

        for fpath in file_paths:
            full_path = os.path.join(self.project_root, fpath)
            if not os.path.exists(full_path):
                continue
            
            try:
                with open(full_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # Basit chunking: DosyayÄ± olduÄŸu gibi alÄ±yoruz (kÃ¼Ã§Ã¼k dosyalar iÃ§in)
                # BÃ¼yÃ¼k projelerde buraya "TextSplitter" eklenmeli.
                if len(content.strip()) == 0: continue

                documents.append(content)
                metadatas.append({"source": fpath})
                ids.append(fpath) # ID olarak dosya yolu benzersizdir

            except Exception as e:
                print(f"{Colors.YELLOW}UyarÄ±: {fpath} okunamadÄ± ({e}){Colors.RESET}")

        if documents:
            # Embedding iÅŸlemini manuel yapÄ±p Chroma'ya veriyoruz (Daha fazla kontrol iÃ§in)
            embeddings = self.embedder.encode(documents, normalize_embeddings=True).tolist()
            
            # Upsert: Varsa gÃ¼ncelle, yoksa ekle
            self.collection.upsert(
                documents=documents,
                embeddings=embeddings,
                metadatas=metadatas,
                ids=ids
            )
            print(f"{Colors.GREEN}âœ… HafÄ±za gÃ¼ncellendi.{Colors.RESET}")

    def query(self, prompt: str, n_results=config.MAX_CONTEXT_RESULTS):
        """Prompt ile alakalÄ± kod parÃ§alarÄ±nÄ± getirir."""
        query_embedding = self.embedder.encode([prompt], normalize_embeddings=True).tolist()
        
        results = self.collection.query(
            query_embeddings=query_embedding,
            n_results=n_results
        )
        
        context_parts = []
        if results['documents']:
            for i, doc in enumerate(results['documents'][0]):
                source = results['metadatas'][0][i]['source']
                context_parts.append(f"--- BAÄLAM: {source} ---\n{doc}\n")
        
        return "\n".join(context_parts)

    def clear_memory(self):
        """HafÄ±zayÄ± sÄ±fÄ±rlar."""
        self.client.delete_collection(config.COLLECTION_NAME)
        shutil.rmtree(self.memory_path)
        print(f"{Colors.YELLOW}ğŸ§¹ HafÄ±za temizlendi.{Colors.RESET}")
```
